{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e2cb730-6752-4c62-89c4-9058d5d12a82",
   "metadata": {},
   "source": [
    "# Training a Siamese model on MNIST dataset using PyTorch and supervized learning\n",
    "\n",
    "In this notebook, you can find the example code for this repo (https://github.com/ziadloo/Self-Supervised-Learning-vs-Supervised-Learning) that trains a Siamese model using supervised learning over the MNIST dataset. You can also find in-depth explanation on this topic on this [article]().\n",
    "\n",
    "Let's start by installing and then loading the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809a557e-65b6-4783-9581-0e2f32964e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/ziadloo/Siamese-model-in-Pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b750df8-6205-47be-9475-f974fbb13239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehran/.conda/envs/whisper/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/mehran/.conda/envs/whisper/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import random\n",
    "import copy\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path of the parent directory to sys.path\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Now you can perform relative imports\n",
    "from Siamese import SiameseDataLoader, SiameseSampleGenerator, SiameseDataset, SiameseModel, triplet_loss, info_nce_loss\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce790248-a267-4e43-af69-4f98d08e11c2",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "First, we need to load the MNIST dataset. PyTorch has helper method to make it easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97d2a3e9-a127-494e-b586-c759dfb5ca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mnist = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_mnist = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "attachments": {
    "4901ca9f-5bea-42d8-b243-36dccf402a35.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAFCCAYAAAAHRS/iAAAABHNCSVQICAgIfAhkiAAAIABJREFUeF7snQW8FcUXx+fZopigYoIFtqikgHSnoGJ3d3dht/4VuxNR6e4QBEXBxgIMlDCwQBHf/Z/vwKx79+2N9969u/fBOZ/Pft67GzNnfzM7J+bMmaJEInGSMeZuOTaTQ0kRUAQUAUVAEVAEKhYCS4Tdi4tEoP8s/6gwr1iNp9wqAoqAIqAIKAJ+BH5BoBcrJoqAIqAIKAKKgCJQsRFYq2Kzr9wrAoqAIqAIKAKKAAioQNd+oAgoAoqAIqAIrAYIrLMavIO+QikRKC4uNrNmzbJPbbDBBmbPPfcsZQmr7+1ff/21+emnn+wL7rbbbqZy5cqrzcv+8MMPZsGCBUam2ew7bbbZZmbnnXdebd5vdXiRxYsXm2+//da+ynbbbWe23nrr1eG19B0iQkAt9IiAzqYaBO17773nHQiXfNDvv/9uDjzwwCKO7t27F+Wjjopa5g033GBx4Zg6dWpFfQ2P73///dfcdtttZvvtty/adtttiw444ADv/S666CJt+wJr4VdffdX7Np977rkC407ZKXQE1EIvoBYaMWKE6dChgzfIYiF+/vnnK82pAuIzClbA4o8//rBVHXrooWattVT3LAvuRx99dBFCQkkRUARWfwRUoBdQGz/99NNJFtMXX3xh3nzzTdOoUaMC4jIaVs4555yir776yla2dOnSxIYbbhhNxatRLZMnTzZOmG+xxRbm+uuvT4jnwTgscbkrKQKKwOqDgAr0AmlL5m0HDx5suSkqKvLmORHyItDXSCu9QJqmwrIxaNAgT0Hs1atX4uyzz66w76KMKwKKQGYE1I+ZGaNI7njxxRfN8uXLbV2nnnqq2Xjjje3/r732mvnzzz8j4UErWb0QwMPj6KCDDlq9Xk7fRhFQBEogoAK9BCTxnPC7288666wE88YQ88gIdSVFoLQIEPzoaNNNNy3t43q/IqAIVDAE1OVeAA1GZPsHH3xgOdl3333NfvvtZ44//vjE888/b12mTz31VNEJJ5yQd7f7Z599ZsRTUPThhx+an3/+2Wy55ZbM3ycksMpss802WSH13XffmeHDh5sZM2YUzZs3z/z6669mk002MRJhberXr5+QqHpTtWrVlGW98cYbdrrBBcRxY79+/cz6669f4pkePXqUOOdOLFy40AwdOtRMmjSpiP8pj3dgKdDBBx+ckOBDU6lSpZTP+y8QKU5ZAwYMKPrmm28Mv2vUqGHatWtn3ycfAXtffvkl9Zm3337b8r/OOuuYatWqmSZNmiS6du1qttpqq1DeP/nkE8MB8ZyjkSNHmo8++sj7DZ6dOnUKLSPTSdpHcDXDhg0roszffvvN8ke7ckj/TbRq1cpilIoo45133jGjRo0y0t+KWK71999/m80339wuF2zRokWiffv2GbFlGR5xJhD1ESMATZ8+3bzyyis2DgPFhmtdunSx2AXpl19+Mc8884zts/RflirSV08++WTbb9MRbbRixQr7/q5s+sgLL7zAahX7XryTeEgSxxxzTFpM0tWT7hpLUIcMGWJmzpxp61tvvfVsP2/WrJntn9ksvaQ9xo0bZyQYtYj+w3dLObRnlSpVTO3atW2b7rTTTulY0WtxI0DqVz3ixQCLXPqBPe655x7bHtCOO+5oz8mcekLcpzlrpyVLlpDu15Zdq1athAxIxZdddpmtx533/5UBIfHkk0+mrV8ET/H+++8f+ry/LBGiiZtvvjllWTIwZizDYRLWb5ctW1Z84YUXJmR9fdpy4EMG/BJ8rFKc7LMyuBWDe7r3kmVgCVnfXaKcMN6yOScBgMUy5ZJYe+21U/K/0UYbJW655ZbQOq+77rqUz/nbQQZpYaf0/X7u3LnFCLuwfhI8d80114TWceuttxaLQpKxjF133TXx1ltvhb6n410EmdeXTznllIQobsVHHnlkyrJRiETAe2WKAltMXwjyzm/6vSgtaeunLdy98HTXXXcVp+rDokQlbr/99rTlPfjgg9773HHHHWnvFWWlGKUyjHd3jnbmHdO1NX0chSNdOe4abZeuLL1W+m8ql5iphS49NU7CKhHBYllAy8cahgiMQ6OXD8harLjk5X8+upzT5ZdfXiSKhC0XD8Huu+9OZLmZMmWK1dSxcETIFIngT5x++umh9c+ZM8dLVrPuuuvaZDVYN8QCYEVhRVAO5cpAX/Tjjz+a++67r8T7YElhAZNc459//rF1cQ48/BT8zTUCC2WAK8Lyc4R1gtWGlYHX4dNPPzUkWIEPrLF0NH/+fCMCvgj+sWj32Wcfa+1gPbvkH3hXOnbsWCQWIUI4XXEZrxEr0bp166T176LU2TbBCuS9eEfuu/rqq4tmz55txIuThKFEsyckWYwFi/cUBcfWu8MOOxjaxRFWY2kJS/yQQw6xXgqINhBlx1qDRM7/9ddfFl+sYvosGIeRRN8XLVq0yF6Cj7333tsQhc8z5F7A6qcPgHPTpk2LJk6cmKhXr15YUUnnyONw2GGHFeEhwmtCH8STQd/EWwThWVh1T+LRRx81okyzn4Xtq6JAWLzoq/Q9+it5GsR7luBaJrr//vvNpZdearGvWbOm2WuvvWw5opQY+jvf+hVXXFFEuaLUluj7mcr3X6ff0dcdjrwv/RMLmjrfffddwzXqPfbYY/neEueff36JKvBO0Kbff/+9vUY5rk1JOgUetCkYgpP0Pd6vXLyXYEJP5A6BXGoHWlbptbM+ffp4Gjnath9DcYF712TQTMgglxPt2G+hY8limUvikYS4LpPKx1r0ew+wMMQdF8qDLI8qFhdpQlyQxVjJwb4gg30x1oeznKkzWJ//mV122cWzGOAjWF7wNx4NcQl6z8iSrIRMVRTL4FbiWXHxWiv+kUceKXHNb6HLVEFCBrgElqbfqqPu119/PcmyExdribKCPGb6jWW+arBMUHffvn2TypSgyWIsPHhy9z300EMp68Xl6u6TQTnlfZn4ctexzlx5uMSx1sOexWPxv//9z7Z32PUjjjgicckllyREKIVeF4WhWASpx7somNZlFVaW30LHooY/mUpIUIb/fpnK8foe9zz88MPFooQkRJAnRAFIulcUveI6dep49WPxh9XNOWehY5WLwpQQBSUBT/776YM33nijhx19f8KECaHvk42FLsK5mO/VtQVYicKSVB5jxeOPP17MN8t98Ddt2rQSdV577bVeOW3bti2Bm3sPUW6LRQEvfuyxx0qUkQobPV96eVBezNC6tIFixEAsMu+DQrgH20MsE+96cOAJ3pvtb79A52Pno0fIpXr+qKOO8niQeUK5rWSfyVbZwM3tBiKxlELLovzSCnTciq5cBlmxslK+Txj/7pxfoFPeAw88kLKce++916uTwTBduZmuffzxx0kDvswtp6z3zjvv9O6VYDfrZg4rP9cCHSHuMJaER6F1hvERPJdNX0GAoyC6+iSGIbQ+v0Dn3jZt2qRUfP3Ci3vFe5QQL0douWKRFrtpDwR/mJLKezmBTnkI6rFjx4aWx70oMe59cHEHceF3NgLdr/gRaxNWjjv38ssve30FhTd4L/EkjqegEhS8V3+XHPcKDRMV6CHCKapG4gNy1hYDc9iggRXpPrh0ArA0PAcF+rnnnlviQ/eXJy7nYgmQsR8+mn5554zFJWzLwj2ciu/SCnSCdhxOd999d8pBNVV97rxfoIsLMyV/3C/uymIG8UzvkqlOrtMGjv/DDz88bb0IRHHpevdjiYXVkWuBTrwAPPLO2XhNwngqzTlxzXt9/4ILLgjFxC/Q+ZbSKRp4lxzG/L3yyitDy3Q8NmzY0MNYpjtCMfYL9G7duqUtT9zVxRJo6pUZpnRmEugS9OZ5GvBC8S1nwtR5G2g3vA/++2VawvKDdyHMm5WpbL1eWEJel61Jb46LyNXMvB8kwtpulBIkcU96Ed6SKMTOA+eaZI6NjzolsUFEy5Yt7XXmcpmHLA8xtwjxLsxTl5eI5pYIX1sMGLKOPxeEApWuHDKtMTcP8S6p5ozTleGujR8/3rvtxBNPTFsv85yrFA/7jEQnJwcYZFNhGe4hyh6SQdz07t27DCWU7hHm1h25VSDpSmAOmQj5VBSMxVjl1k91e1JEuosbSHmzXMj0HbGqwi1HpRyiyktLo0ePtrEKEFH12SxH7Ny5s+1PtBtxMX5ybcq8OzEFShUbARXoMbafLJXxBmJcZ2GsEDQkQVf2EkE14kILu63M51iaQhBMJloV2WxvYzlOqvvFYiCAz8iSnyKxcIpEeBeJtZ10+AeyXCgoLFFyJFakXSaXC9pjjz0yFiNzmd49BI2VhWhXt9SMQLMGDRpkLEaw9e4hQCoK8gtAgr+EzyIEuz+BTWn4kGkGgsNs4Jm4oItEGCf1EzaSceVl009kxUba6lH2/OluM93vhB2F+tf0p6okm8A9wcz7ztN9R6nqkA2DPEwIdJQ4hoyHf3mmTCUkFS0KhsePeInISlkkXkEb2KhU8RDQKPeY2kwid23kKMQWlunytSPsJajHfshEu0ue81DhX5ZXIQrYH/2cqgwGD0esdQ0jCYSyEezZDH7u+VxkwfPzk27tcxjP6c5ls37Xvz6eyOyyEJHGzlODMpKN1UX0uyMimaMg6YcGLxFrryEJsuKw/ZI1/hIPYrAGZR7by3QYxheR+rJaooicA9mSPy9BqmdcdsVU1znv2gvFSdzl6W5Nyn2QqW3xmmRas05lfgWwLO3GigtHN910k5EjpXId9nKCPfd74werVljDzsoACAteDlsmCo3EhpCvwLZptnkbwurVc9EgoAI9GpxL1EKyGHeSpSZPPPFEiXvcCdxhLGnD3Y1rmWU12VjVKQv0Xch20xP/4BcmhGVdtBXmrmiWDGFp4q5nrtxvNUukbBHLaiDcgOUlvwKRaZAub135eN6PZ1naIxthlwu+EVqS5IecBEasuCI3zUHZCBpZQsdRRFvLsrqEWPEllhviLpa5fZu8CMJDJGvD7RIv+gkeKTf1RL+X/PNZCyyEdFwUNl0WxotfKJal3VhGWh5iDPETSy1FoNslfBKLUfT+++97l1n2SMIdPIl4NtjcR2IZylO9PptnBFSg5xngsOIRQH7rhPlTObIejbDSxRouvyQU5rKd9/ULzaDlyvyibP5h+UcgyXKrhJsmCHt/NqFxAj3semnP+S3a0ngHSltPvu734xmmLIXV6xcGuZpiCKsneA6hSYwCkdasxceykyVYRRLdbdc9Q0w9kNuA6xLkldRPZdUAmeHsfXXr1rUKAuvYwwjhVVE2lGG9NsppJqXC377B7ygMg+A5/zOy9C6BBV0aCvP+oKjJ8lQOlr95bcrUmPMiMJUmSz2LiHmR5Dk5GXtKw7femx0COoeeHU45vYstLbMVpGEVM4/uNnIJu16acwSUMYebiWSuzlM4sLr9hAvW8UPyinTCnOfQ/HNJ/rS0ZZ3PzSU/pS0LqxQPDIRCgks6E/nnQlOlgc1URnmvMw1z2mmnEdeRkH7EOmebUteRCBwjUedJ1Yiy5/UjCQpNKcx5yCU7KS+fUTyPMHfJhtLV5xLccE/wO0r3nLvm7+sodUwxleYggU86ql69ujnzzDPZdjchClpC3O8JplIcyVp0L0lPunL0WjwIqECPAXe/u51UnWKtZnUQxQsx4DOXmQvCBSdpWzMWRbYrR5J5LUlDl0HbG6QzbfXKIJRNxDJWg6NM85cSsOfl/MZlmI1AzPjCEd5ADAPZ4BwFI5HDWPGvNCiUndQIChPvS8IF7BEXEIzkJvsbhGDJFJTmcrSHvX8hnpOAtYxs+YPaVqVbzfiM/4ZV68btKfKul+rhUt6Mt4G2FC9MwvUxvkXxyJSyJL09KgRUoEeF9Kp6SNdJMBHEQH7eeecZIrOzOY477jhPkPp3ZyvvKzz77LNpBwbScbqPmKAiSRWZVCVznY5wzaUjUWay8i7458IzCWgsXBnobLXwQnBeRSM2vnAk8RRp24N3dBv38Myq5EQF8coIAZkj93gJzvk6Tw6u5+B8rv8FsHhlXjctDgXxwj4mMn1HYNG/f3/7BDi5paCleQ/6iZuvZ6rOH8dQmnJKcy/Ktf+bD7ZpacrSe/OLgAr0/OJbonS/ICZylB3NsqWePXt6lii7VOXKJcl6eKdkBHlhYJWo+iJnJbPDWdBtJ246T9FgR7JgGe43u7mJRyLldf9zuP4cZTNoyZytx4OkRy3KZq28iyxPxW+U5yXa2MsFT9SxiyQP40GCk+xOdhDudnIYREFuaV2musj97Si4O5f7zTQPO8ClItmYhOWRqS4X5HneJ127sdTPLW0kEJB876Uldj9zeRb4NiUtrd1hLRvyt4u7Pxdtmk3dek9ECEinyJhpSO/JDUbsaiZzYAgee4Tt9pUJ66ZNm3rP33bbbWVqO3+mONJfkv2NCGPZd52Mm16ZZIgTAe7Vx71irZeok7SxYnF49xHh7M8kRmYzcr3LYGTv8WfLEhdkifLAgJSrDicUBnZ7I/e7TE94RxAr2djG44Gc8exIJtZ9UvlkwyI9pyhHCXJTB8vwZ4pjt7Xg9eBv/85jwSxcwXsz/WbHO/fO8E/WMHLgu+dkLXaxxCh493AvqT1TlZvrTHG0v1iVCVEAi8knHqyXLGZXXXWVxx/ZD4OZzESoedf5FoIY017uHf39hJ3XgvXxO7jbWtg9/nPu+6O/ZrqXfuzag30Bwu53meLItMb/7NwmHpakPQTIKIjC5srie6Mfh5WXKVMcz4hSUCw5Erzy2OdBvAPFZKILlinz+jb/OlNhEvNQ4p3hm3S5pE4OfiuUJbERxf42Y5xIlWo4WLf+zo3cKA2Omvo1QoVG5r09IcXgWJb0mQwWbmCQRBwlPtBsGt8v0Nk+1b/pBgNe48aNE6RS9W/hyf8I/FTls3Wl44u/vB+pQpnz8w/MZ5xxRoLUpu7eVAIdHv0bUPjL5v+wAZkBLbidJHyTJpWc+KRyRVC6stjqMvg+cQp0Nl9hzW8YjvDu0u+66wy0Qf79v/Mh0P28ibWdQKERd2wCAePnD9xR4oL8IfQRQP5y2CCFPsc2tQg7riFoyGfv7it0gc7GMCg6jl/6PEKUeXK3QYq7xsY1QVzc72wEOveyMY5k0kvCEexI5UpfZ096/3dH3WEC3eHteJMAuwTJb9hmlrHBf53/ZcogJe+p3knPRyfYVaBHKNDZ2MR9OKSJLEtHR9v3DxDkuy5tOUGBzvPsw84g6h9o3f+SYKLEDlLBOhFGWCF+S91fFmWzDzrWejYCnfLZQQpLms0xgnyFCXSewQvCPtLsehV8xv8bb0FwVyyej1OgO/7ZmcufIzz4HihdWGTBNgj+zrVAJ6uY29EsyJP/NwqUpChNyR8bogSFkf95FAUJDLTeCXe+Igh08JfYhpT7q5N7nevBdvL/zlag8wyWMlNNKM/p2oNr7FjHNx6sW1YlZPU8ioLE0ZR4Plie/o5OeIdhjd+Jj0YpAgSY13UBZET4plp/m4kVotLdemtJq2r8882ZnuW6P1KV4DOixCHWEbOkTubVighEY36WDSrIGZ1tliiC/gj8kfm6IgKgKEOShiQkvaeX95z9rlkuB8nGERlTtTLXPUey6hGM4w+6k92/bBlhRNAVa6PFTW/3Mwd3lglh9bM/Opn5wjLkMafoltWJl6JEvECwrhkzZli+ILEybaKUXBCpTpmTJRMbc6QkAGHJEpYTwVTZJKBhDposdBBJfrJtw3T803d4Z/qgxHAUub3lydKG0ADXdFkPXdky7phhw4bZPPSsbQY3MpOhhPB+LOPjHhclD+9hKXHppyRagvieMkXOiwLsBWWm6z+UR58jtSpEoiR/Klh7Ukjeu4i+xvpwcYUjWG0fFW8WqzmK6OfEybBBCnnc/alnXRn+vzJtY4g1gdiDPRiDEPYMYwFBq2R4o6+zJJbAOTLX4TmhPRgnUhFtSnvKBjRem7KunneiTZnvD8M+VXl6Pj4EVKDHh73WrAgoAhUcgTCBXsFfSdmvwAholHsFbjxlXRFQBBQBRUARcAioQNe+oAgoAoqAIqAIrAYIqEBfDRpRX0ERUAQUAUVAEVCBrn1AEVAEFAFFQBFYDRDQ3dZWg0bUV1AEFIF4ECBqnQh9ovyVFIG4EdAo97hbQOtXBBQBRUARUARygIC63HMAohahCCgCioAioAjEjYAK9LhbQOtXBBQBRUARUARygIAK9ByAqEUoAoqAIqAIKAJxI6ACPe4W0PoVAUVAEVAEFIEcIKACPQcgahGKgCKgCCgCikDcCKhAj7sFtH5FQBFQBBQBRSAHCKhAzwGIWoQioAgoAoqAIhA3AqttYhm2XlRSBBQBRUARUATCECgqKgo7XaHPVWiBHhTawd8VumWUeUVAEVAEFIG8IeCXF0HhHvydNyZyXHCFE+iuEYJ/wSUo0IO/c4ydFqcIKAKKgCJQwRAICmt+O1kRvMarhZ0r1FeuMALdL8BT/Q/IfiGuAr1Qu53ypQgoAopAPAj4BXTwf/ebv0FBHvwdD/fpa60QAh3BnOrg9fzX3G/32irU03cAvaoIKAKKwJqEQCYh7oS5+4sMCT5TqHgVtEAPWuL8Li4u9gS4//9UQl0FeqF2PeVLEVAEFIFoEQgKZvebv2uttZYV3O7w/w5y6S8neC3O3wUr0J0gRmj369fPTJkypeiPP/7wXOpOgAOe/3/324GqAj3O7qV1KwKKgCJQOAg4YV29enXTrVu3xPbbb28FuBPe/r/IjqCQDyoEhfNmKzkp2O1TAfOff/4xhx56aNHQoUMLDTflRxFQBBQBRaACI8Ae9k8//XSiUaNGVnCHHWuvvXYJYe+34gvNUi9Ige4s7t69e5vzzjtv9VssWIE/AmVdEVAEFIHVBYFtttnGTJ48ObHeeusZJ7z5G/Z/0Ir3C/ZCwaPgXO5OmPN31KhRnjDvecxxpkHDgwsFN+VDEVAEFAFFoAIi8M+Kf8ztN91ofly82CxYsMB8/PHHZs8997RC3B3rrLOO/d/JI/e/+8trF5p1Dk8FJ9BhChCZO1+4cKHXXY45/gTT+JBmFbD7KMuKgCKgCCgChYRAv9f6WoEOzZ8/39SoUcMgxN2B/OH/YAyWE+JY6/5rhSLcC0qg+63zIJCF1BmUF0VAEVAEFIHVA4G///7b/PXXX54wX3fddZNWU7m39LvYnawqFEHueCwogQ5TfqG+enQXfQtFQBFQBBSBQkUAgb506VKDIA8Kc+RRMAjO/Xayyr1XIQj3ghHoQevcrTEv1E6gfCkCioAioAhUfATEOi9atmxZ4t9//zUc/vwmvJ1/6ZqLhPfLq0IQ5K4VCkag+7tFUPOp+F1G30ARUAQUAUWgEBHAQheBniTMHZ8IcH/EO8KeIziHXijvVVACPWil81tJEVAEFAFFQBHIFwLLly+3c+h+yxyr2wlzF/mO9e6PfIcfv/FZCJZ6wQh0J7z9Qj1fDajlKgKKgCKgCCgCIOAEupNBCGb/8rUVK1bYgDlnnQdd8oWEYsEIdD8oAAto5SW18MuLoD6vCCgCisDqjQAZSXG7Q84yd8vX3Lx6cG496E3mOc7FbaUXlED3uy/8/5e2O6kgLy1ier8ioAgoAmsmAk6gO8scYY5V7g6/Ze63zgtRzqxVCE0YBCb4uzQ8lufZ0tSj9yoCioAioAhUfAQQ3Ah1vxDnf2eVu79hwrzQ5E1BCHR/l3AAlQWosjxT8bujvoEioAgoAopAWRFAYIcJc+duR64ED+ryy5tCkT0FI9CD4BQKQGXtJPqcIqAIKAKKQOEj4J8n91vjziJ3Lncn1HmjoLwqlLcsGIEeBKm0AKkCUFrE9H5FQBFQBBQBZAdCO5Uwd4Lc/9ehVmhyp6CC4gCp0ADS7q4IZELgzz/+MBPHjzUfzJppd2/64/ffTZUqVc2WVauYrbfexuxX+wCzz37723WtqzN9+vFHsqHSAu8VmzRtvtq/8+rcnmvKu60S5kXyN+G3xv1z5mBREWRTwQl0B1xFAG9N6fD6nuEILP3zT3PLjdeb555+wgrxdLTZ5pubgxsfYq667gaz1z77prs1J9cmjBtj5s2ZY8tq27GT2WabajkpN1UhDH6Hd+1kvv3ma++WfkNHmOYtW6d6RM8rAgWBgLPQg5Y4zIVZ5f7zBfECPiYKUqA7/lSoF1p3UX4cAosWLTSd27Q0sz/5uAQoG1aqZAeCvySdpKMlv/xihg4aYLp27xGJQH/uqSdN/9f72uqH1ayVd4E+eeL4JGFOvS8++4wK9BK9Q08UGgJBQR787efXXSu0d3D8rN4+wEJFXfmq0AjwUZ94dE9PmK+33nrmzHMvMOOnvm2+Xviz+eGXP8yCJX+abxcvMUNGjzMXX36V2XW33Sv0O2diHuHtyCXXGDZ4oEGRUVIEKhoCfsGdykovxHdSgV6IraI8FTQCzJdPmTTR8kiKyD79B5nb7r7X1D7wILPpZpt5vFfeZBPTqElTc22vm807H35qBo4YbWrW2qOg360szP26ZIkZPLC/fZSphaOPP9H+T37s1159uSxF6jOKQKQIpLLKOV+RSAV6RWot5bUgEBgxZIjHR8cu3bJyK2O1HtKshdl3/9oF8Q65ZOKNvn286YVuPQ43J5x8qlf8S889m8uqtCxFIBIEKpogd6AU9Bx6JC2nlSgCpUTg66/neU/su//+pXw6u9s/+ehDM3zoYDPrvffMjz8uttHi1aptaxo2amy6HNrDbFmlSmhBzNMvXrTIzJ3zlXd9+NAh5vPPZpe4v1PXQ1OWU+LmNCdefO4/d3vPo481B9WtZ3bbvab54vPPhP93zccffhBJ3EAaFvWSIrBGIKACfY1oZn3JXCJQLJmlHC1etDiXRZsfvp9vLrvwfDNEXNhhVsLrr75irr/6CuvGP+3Mc0rUfd9dd5gZb09POv/gfXeXuI8TTBGkUgxCHwg5yVK192a8Y6/ssutupm79Bvb/nscca2667hr7/4tipTMloaQIKALpFrskAAAgAElEQVT5RUBd7vnFV0tfDRHYfscdvbci8Ov3337LyVvO/vQT06JRAzN4QD8rzLHKWeLWoXNX07ZDJ7P9Divrpb7LLjjPE5j+yrcRK756jZ1NpY028k67c5z3H+uvv365+X7BFwx3xNHHeLtNYam7dfev9XnJblGppAgoAvlFQAV6fvHV0ldDBNq07+C91Tfifu/UpoUZM2qEzTRVVmId+zGHHWq+n/+dLaJl67Y2kG7KjFnmpdf6mT79BpoPv5hrnnmpj9m4cmV7z7133mZGjRiWVOWLfd8ws2Z/adq0+4/Hp1942Z4LHrX23Kus7Nrn2NDitVdesv8TI4AQd7Td9juYxoc0sz9/XLzYjBz2X9yBd5P+owgoAjlFQAV6TuHUwtYEBFq1aWfIguaIeeIendqbGtWqmJ6HdjH3332HmTRhnCGDXLZ09+23mi+/+Nze3r5TF9N34BDrwvYTQpOgsxdefd0KUKz4m6+/Ntsqcn4fQnrx4kW23IaNm5gdd6qeVMeR4nZ35F/WlnNGtEBFQBGwCKhA146gCJQSAYTp831eKxHd/tuvv5oREsh2w9VX2qQzO229hWnTtJF58tGHzbKlS1PWQsa5Z558zF7fYIMNzL0P9k6bMrVZi1bWgodIN/vh+7NSlp3PC34hfaTPOnd1du7W3Wy08cb259jRIyUt7g/5ZEfLVgTWeARUoK/xXUABKAsCrLd+Y8hwg4sb13JYnna2ZJz+1lRzyfnnmAP2qmlGjxweWtW0t6YY1nJDTUVYM+edidp26Ojd8tbUNzPdnvPrCGemGSAy4xF5HyTm8RHqEFj0efH54C36WxFQBHKIgEa55xBMLWrNQgBLnXXoHLiep06eZN6ZPt28P/M9M+Od6UlWOdHrPbt1Ns+90tfe76e3p73l/dxxx53MvLkrc7CnQxNL3tHXc+eluzUv11596QUrpKGOErRHEp0wwu3+ygvP2UsvP/+cueCSy8Nu03OKgCKQAwRUoOcARC1CEahadStrpTpLlTzukydNMA/ee4+dT4cImjv7tJOtRe/PKLdo4UIPwMcfechwlIZ++eXn0tyek3v9CWNYopaKyJRHdP53335j18LjsajXoGGq2/W8IqAIlAMBFejlAE8fVQRSIbDBhhsaguc4HrjnTnP9VVfYW3Gt95VlXKeecbb3KHPv5aF/V1nK5SmjNM8ilF2iGvLYs6vbs08+nrKIHatXtwIdeun5Z1Wgp0RKLygC5UNABXr58NOnFYGMCJx30aXW3fzZ7E/tvdOnTk0S6G4ZGteuufEm0+OIIzOW6b/BBZ6V6qFy3IxQdsT68ovP+085yVQsO8Ddfvd9SevkMz2j1xUBRSA7BFSgZ4eT3qUIlBkB5tprH1THE+h+FzuFbr31Nl7Zvy751SZ/KVQiIt9ty1oWHkmKM6j/G5JJ7riyPK7PKAKKQBoEVKCnAUcvKQK5QsAfxObP4kb5dRusTJfK/yzvuun2O8tdrT/q/t/isie8CTIysN/rXmY8EtM8+tSzwVtCf48cPtTc1usGe+0Fyf2uAj0UJj2pCJQLARXo5YJPH14TESChC1Z3tsT9b7052bu9xs67JD3a8ODGZvMttjC//PyzYVMWhHqLVm2yLT70Pr/S8PNPP4XeU5aTL/rc7T0l1ev+BxyYVTE7Va9h7pHkObjoWQ3A5jFBHLIqSG9SBBSBlAjoOvSU0OgFRSAcAdaVY21mKyjvueNWz91Oie06/reGnN+s4z7z3PO9ys457RRDStlsiM1RwmjHnXbyTr8/c2bYLaU+hxBGGEMoNKWZ60dhaSkBghAKDjEFSoqAIpBbBFSg5xZPLW0NQICo9Dtu6WX2qLG9Oa7nYebVl19M2q4UCEj7On7saHNk965J6VnZE92fNtbBdf7Fl5k69erbn6xZb9qgjnns4Qe9hDN+WMn3/sIzT5kubVuZZgfXC0Xc5VHnIsvgyPs+YdwYu52pO9JlrwsrlKVqbge4BrKNq9ssJuzesHOH9fwv2O9lWZteXFwcdpueUwQUgTIioC73MgKnjykCf//9tw3w4oDWXntts8UWW5p/VvxjEPpBgcXOaU/JRilhxM5nL73e3xzdo5skp5lmrf/LZRvVKy++0AbJsW4dd/WCH743P/34o1cEy+PCiLXeKA6sgWfjl17XXl3itonTZpj9ah9Q4nzYCdbQv+LL9HZYKSPxKbOd7BhHAhoC4+Z/961VMJq3bB1WnZ5TBBSBMiCgFnoZQNNH1mwEzrngInP6WeeaHSSrm58QemSMW/LLL0nCnD3Hr7jmOjN28lumStWqKcHbaqutzZDR483VN/Syc+oQSsGcr740M9+dYT7+8IMkYY6gv/DS8MxruMRfFgXh7PMvKvee5/CB8EUIQ6w979r9MPt/aQjlw58lz5+cpjTl6L2KgCIQjkCRuNBi93vhxmPg4iCdJAdbM7Zs2bJo5qr5vyGjx3nbMYa9inMFhl3Tc4pAvhD4et5cM+Pt6ebz2bPN9+Iqx/pcZ511zCabbiqWdQ1rATds1MSsu+66pWIBd/iUNyWV7LRpZr642LGyEYgscdu9Zk1Tr+HBZtfdds+6TCz7BT8kb45Ss9Yedv4+G/I/T8R+WbdeZStVl2QGxWDPvffJpnq9RxHIKQLtWzb14kG6d+9uaso3ValSpYQc/DUbyT4EG8vGQu4v5zaU748Dbxp9l++cA88cq0o4ShMsm9MXWlWYutzzgaqWucYgQPQ2R64JQcuOam5XtfKWz4Yv2Wz6kqqe8j7vysVDkc5Lkap+Pa8IKAKZEVCXe2aM9A5FQBFQBBQBRaDgEVCBXvBNpAwqAoqAIqAIKAKZEVCBnhkjvUMRUAQUAUVAESh4BFSgF3wTKYOKgCKgCCgCikBmBFSgZ8ZI71AEFAFFQBFQBAoeARXoBd9EyqAioAgoAoqAIpAZARXomTHSOxQBRUARUAQUgYJHQNehR9hEJNQgsUYcxLrmXXbdzSZCIAkPG22QnjQOIukKO22RhIEkQl99+YUpbV7xXPHNmmiXk5zUql9+/plNsRoHVdtuO29vdPYdBxeyz8VBZKHbbPPNbdX0E/pLHMmbSNqx8y67mo0kyQfkT0wTNS4kB9p195o2sQhETv3g3vZR8URyH3jhe4bmzZ1jMxTGQRtXrmzbyL9lbxx8aJ3GqECPoBew2cZRkqOb9J1xUtWttjLX9bpFNuq4vcRmIlHzhUC/6LIrTK/rrjaLFy2Kuvqk+mofeJA58pjjJN/5VeYP2VQlTmrRuo2pV7+hueu2m222xDjpmONPNAiOpx5/NBZh7t4doX7BJZebzz79xAwZNCBOSGymsGt73Sz5+/uZaVOnxMoL6YGvv/lW88j/HkjazS8OpnbYYUfzXJ/XzAEH1Ymjeq1zFQIq0CPoCtdcfqnZYrNNzddff20qizYbB2EJ33fffebKSy403bp1M1OnvOlZGlHzw6Yml1xyibnswvPMhRdeaC644ALP0oial98lperRRx9trr7sYvPggw+aww47LLb0jYtEsWnfvr2ZOG6c6dfvDdOoUaOo4fDq++qrr0i9bH9PmTLF1KpVKzZe3nnnHdOhQwez4447mo8++shsu+22sfEyePBgc+qpp5oDDzzQzJkzx2wmm+bEQXhuHn/8cXP1pRebNm3amHFjx1hlIw5C8bz22mvNmSefYKa//3EcLGidqxDQXO4RdIV9d69h7rzjDnPEEUdEUFvqKhAY22yzjXn77bfNQQcdlPrGCK7079/fHHrooebnn382m69y7UZQbWgVV111lXnooYfMb5KHPW7q0qWLFRQffvhh3KyYffbZxwry1157LXZeqokQP+nEE80tt9wSOy+byI5xKMcnn3xyrLwgSBHio0ePNs2aNYuVl88//9zmQ5+34CdvqiZWhjJUvrrmcteguAwNn4vLzMmSzD9uYo6LedBC4MXNxxYKL24uMu42ov5CwAQ+iHFw88Vx47KW8KJtlNwKzOmzoVUh9BfHw9/L/467q6zR9atAX6ObX19eEVAEFAFFYHVBQAX66tKS+h6KgCKgCCgCazQCKtDX6ObXl1cEFAFFQBFYXRBQgb66tKS+hyKgCCgCisAajYAK9DW6+fXlFQFFQBFQBFYXBFSgry4tqe+hCCgCioAisEYjoIllVsPmJ1lKixYtzAMPPGAaNGgQ+RsOGTLEPPXUU+bbb781O+20kznjjDNMq1atIufjV0lZyrrlMWPGGJLZkAzkyiuvNHvssUfkvPgr/EVSdHbq1Mkcf/zxNklJlESCIZLXhKVxPe+88yxfURIJUljT/frrr5tly5bZZDbXXXed2VTSA0dF//vf/8ybb76Zsjp4eeKJJ1Jez8eFfv36mUcffdQmo6pevbo5/fTTbd6GqIl+wru/8MIL5qeffjL77befueaaa8xee+0VNStaXxYIqEDPAqSKdsuAAQMM2bXiSJRy880326xRrBmuKnnS3333XUMSGQaFKBNx/PXXX6Zp06Zm1qxZNpkOKUwZlOBl6tSpNmlKXAQ+ZF+LQ8n57rvvbCKSMIpDYJCl79VXXzVbSVrijTbayNx7771mwoQJto2iWgM/ffr0tMlztt566zC48nbuscces0pwJdl/YYcddrB4jBo1yqB4nHvuuXmrN6zgiy66yNx///32+yFDH201dOhQ2z5777132CN6LkYE1OUeI/i5rnrJkiXW0iGtahyERX7DDTeYxo0bm8WyCc3333/vCVRSvGIxR0V9+/a1dV9//fXmhx9+MHPnzrWD9p+y6Qk8xkWkLmXAjotoI2jSpEmG9K7+A+EaJWGFIiBQ9FA0yJB3h2RUfO+998yLL74YGSsooTNmzChxjBgxwiZt6dq1a2S8kP2NzIUIS6zz2bNnmy+++MLsvPPO1jKOMr8/3w9ePhRjskzSVxDkEOmalQoPAbXQC6BNEHSffPKJ2Vh2lMIdHJYRCzctwgBNmXScwZzwDNCHHHJImd/G7sAmQm/+/Plmt912s1ZtGDHAIKixHHbdddekvOevvPKK3R3szjvv9HJc46LDzY07d/z48VkNjgjdDz74wCxdutTsu+++1tIPEu5ZLCvuBY9ddtkl6RasCFLKUrejHj16mIYNG6Z1rwbrgQfahix7tE1Yvmx4mTlzpn0UXraQTTPCCIzPOuss06RJEzNO8rWXlhA6pO1FyDDIgn+Q8Mww6LKhCdijXPnpm2++sf2LqZiwfhYsL9Vv+gn9ccstt7RtFJatjLpIYUtf5Z5g3nMszipVqlihQdYzCIvwtttus30lG48O/Q0L9ssvv7R9kqmmoGWPEARvBBJ9CUz8/btGjRqGI0hMh8AfSkY2RPvyffAdIYBT5b9///33DdhUq1atBHbwSDrkG2+80dYNkcP+nHPOsdiQYjUbdze4fPzxx/Z7JiUr/ASJLHN40BYsWGCxw2tFv3GEUsw70U5uvKlfv75tF9qMcSDOvPrB99Hfutta7H0AF+PVV19tcBFDfHxYkn6XMBbETTfd5G3ryceF0MQt52j77bc3l19+uf3JIDps2DDvWqZ/+DCPPPJIa7VBpPw888wzbX5z/oew7HDJIlQc1a1b11pYzPFBWFgMppz3E4IFwgrLRLiDjzvuODvIQAhQ5liZQ3TEHD33oOQ4greXX37ZG8zhd8899ywxuDOgI6CzIQY0MHb1IARw27tNSyjj+eeft4MtcQsQggkPya233lqiCvhDIE+bNs3Url27xPV0J/BwMIj6U+ayOQfz8BDnTzvtNPPkk08mFYN1+cYbb3hbWyJI6CtlFebUc/HFF1teEAgQig5TGfRdiPP0H6ZZHL/0WZ45UfKxQ0wHMe1wwgknWFe7I/hCUchmK84ff/zRtGvXLqlPIkSJmdhOtqKFFi5caNuLMh1R3zPPPGM34klFtNHTTz9t6APZzOczv8xeDWPHjvWKJB6B78MpgXitOnfubNvfEYKWe9zeCvALobj7Cfc7hBcuE2HZo7z6v1VwJq7F4YriwL4BCH1HjDl4TZyiyDWMjOD0VL169Wy70n7pMMzEp17PPQLqcs89plmXyMfP4N+8eXPz8MMPW1cwrq1jjjnGGwhHjhxp56QZlBD0zz33nLWgESL+DTwYGG6//XZ7lPYjQ1hiYRKMBB986Pxl0HOEtYIgpHwGb3jF0vArFQgpBE9wMOadoDBL2w8WgvOoo46ylgnCigEIa4R5QywfCG8G9zCv2adPH6u4wD8D0T333OMVh7uUw09Y81j1wQEq6aZVP7D4EJa777673YUNKw1hjVvaTR3gCj3ppJOsJfbSSy9ZftgkAwtz4MCBScUi8C+77DKLT9CbEFa//xz9hHlMsEYYMJ/KO9AHnLLBOYQ51hO8Y8lxP/EUCCVHKDpYoyhvCGY8BvDqBG8mXnCFo2CBDf+jbKKonXLKKd6jzz77rG0/7qF9wIU64QfrFaLvEqAHXmBD+6HwUBbCGOs1E+Gapk/SV3kfFAbKv+KKK7xHueezzz6zfYm/fE+UD78ESqYirOH999/fdO/ePdUtSefBEs8I3wW4oNCwM5vfuqftsYj5hmgvFGba79hjj/XKoi+h1CDkncKEtQ02eEGysc5R7BDY1I0CyvdCm/iVPd4f5Y6+DS933XWXde37v2faJ0yZcR4Q6lAqMATkQy6O+5COWyydp1g2MSkWF2exaO/FovEWi4BICFz2GDJ6XOLX5YmUx5K/ixOFemxTrVpCBiyBOZlkQE6Iyyoh7+5dkIHQvq98XPacCKuECLiE4OLdI4O1vUc+xmCR9rcIYntdBFrSdbEQ7HkRxN55cRcnxM2WkI/fOycDSEKs24RYGPac7BGeEEs9IXN4SeXJoJUQSyKJ/6Qb5AdliTJi6xBB410Wq9HyQtmOxE1uz8ncnXdO5r9t3eLJsOdEQNl7Jk+e7N3DP2IlJlq3bp10zv0Qiy3xyCOPJCTKPSHWUkLcuUn3iQBIiHs+6Zy4GS3P4v70zvMcdcMndPfdd1veREh699BOYk0lZIohqbxLL700IUIqIX3bHpQjg3/SPfwQCy5xwAEHJJ0Hd7FwE/KZeOclKjupjXkHsaYS4unx7pHvKSGDb0KEjXdOtiFNyCBt+YYHd4gSWKIdRWlIiAKTxAv3iaBLOkffoTz5Zu158QokRBGybe9IFBFblwgme0oEjf0tQi0hng+PD1GaEqKYec+5f/hOROFMOi9KbEIUzaRzIswSoux552SVRUIEZtI9rm5/P/PfMHHiRMuPKCIl+OAEbSGemaRrMvWQECUg6Zxsa5rUlrJLm/2e/SSrMGxdYpl7p0VJsniKJWzLpN9yD/0tSNxHX3AkSmtCFOokDOk3tGXHjh3tba7/iVs/qbizzz476XvmtygXCcYIP4lCYvmhzzkSRcqe++yb7wt2HPbLh4aNm3h9TpS2hCh+CcG9WMaZYlldUCx9pFgMl2JRdopFUSuWvlIsCmGxKEHF0lbFoogViyJaLNhYuYX8ggSPWA+dQ5deGBdhuaJ9M0/r5qiwrrFm3DysCCk7N+6fu3VaM3Nt5SXKgAd/RDwWNvPh8AUxB4nVGYyCZhtJpgqYQ8Y1FySex1rABYrLL5NlitsSwt3u3PS4uQmSYq4WwmImqIy5PD+BT6qgO6w0XN0QWKaa2/SXR9vIx2lE4fC2d2X+nSkB97wIXmvh4MJ2hKsUS8o/HYB3AesRq5V2du75pBdI88NhjHXuliEefPDBSVY1UxB4VvzzxzyHlUX7OMIq47woONYti0V7/vnnW+8Pc/tY/emINgITvB3OVU4bM3ft3MTOje731ARdxg4DLFr6BVYrfNHPsHaZc/dPbYTxBA9Y6PDj+h84U5YjvEzB+XF2P4R4LoxEcNo5Z/DJhsAYV7jrM26aiikH943yjWEFB2Ma/LgQ6Q+x9zvtgzeJAyIehP6XieADy9657rkffvCqOY8E/ZpviH3U/QQvtAEHbcsyT94NXvAuQHxjbgkf5SgVFgIq0GNsj0aNGll3KEIKtxjza5zzD2ROiDIvRtQpbsNUy47K8ioITAYv1mszJ3b44YfbtcgMqI4IZmJ+noEQofLpp596bsxUdeLCZ+qAAVcsAzsoZCKEFO5G6mdutFu3bvZ/XJ+OmK/lYMCCF1zL4EJ9wbl79wxCl0h3XKDMi7JcjPvTzSPDCwMjrm3mRhGWCC1/2+Au5kABgQcEN27X4DwnAYG8A0K3LETdxFowoPOO/EbxY+rFjwuCe9CgQVYBAheUGASJnxCWCA7whVCUeAahius6k0BHIWLlAPOs9BX6LAF6DP6O4I/BHkxwrdNnhw8fnsSHE6oIYoLanDIAxrQvgjmTQKdf4UonoAs+ODiH8HNE+zDXjoJKXwSXdN8P14nRQNHwB4glMR/4QT/iu8XVzjvTX+CFbwjeIMpC8UGoigfA9hVwYTrCTyhcTMFRJn0VXOmr4uExbdu2teUHFRT/83zPjCfE2IArSglxFP6+giIOLyjcKNu8M9gwbeSnnj172lgQ+ox4xOy7MIVCn0JJ8Mc+JD2oP+JDIG4XAfVDa6LLXSzfhFhH1i0qPcAeEtGakHly58lKyAeeEOHiXccFJoOH/R10mbmHSuNy5xlcj7hRHQ+47HDP+V3JMv+WEMHu3YOLETcez4i15fHLP6LBJ8RKtQfu2JWeqKRbEmEud+5gakKC7Lx6wAY3Kq5ECPcfLlR4pG7+MjUj86LWRZmJcNHynMylereGudy5CO+4px0uvDPuRvc+Irite9nxgvtTgpsSMtB5bl5RIuzzMhBa9z0Hbco56uU3rnFHYS53rsk8ty3b8UJd4ODcoRLAlJAB115nqoApCKZ0wE/myTPBkhDF0bp5Hc48EOZyF4GUkJgG65p1vIiHwnOl8xxTOiJAvOtMBYigtr9FabC8uKklCQgtwZsoCHaayU9hLnemN2T5VFIb8Zws3fQeFaFo+yF1486nn4uiaH/7XdXugV69etlrssqiBF/uRJjLnW8FFzsYOlzq1KmTNH3EdANud3edqQHxNNnfItxt8Uwr8JupJT+JhW3PB/EKutx5RoRzQpQ/rx6eE8UmIXPeXpESk2Gnnxwv9B2mevjtnwZjmsw//jAVx1QE9/GdO1KXe2G43DUoTnpmXIQWTrAT1iMWBBYPlifBRCzbgYgKJlqVSHisP1zjpYlgz+bdcG9jBRDkhqVOdDhWCtaxfLDWKiAojqxvWCEEw2D1hAUMYeVxLxHPLKEiEMy5ILPhBauc8rG+cZUT/Iar2i0/Ay8CfbD+sUBwAWKR+pfl4IrlGc4HifKhbAJ64J0VAFiwBJsx9UDAlXM58j8BZQTlsSwKy5x3dtMn1OOC+cjOxjQKB8uQIFzD/AbrTITFR9l4alhGhBULDs7zgRcA9y7ncPdjceGZSOeF8NeJ1U5b+93zYTwxnUD9uJdx0+NZInqbYEECvvBqsGKC6wTPwQdtFFx774Le/NMVrj7OBb0cYby4FRDUj6VJQBdudPoG3xRLtgj6oz/TPrj56ef+ILRguawIwMLNJnDS/yw8E4SJhU2GN7wWtBftDqbz5s2z007ch1VO8B+eHRf178qiv2DNB93heFSYwgDPTETfwNtGcCRtgFeH8cR5TvDc4ELHg4ArnjEHvsOyBOK5IYseePIOeFzcVAo4KRUWAirQY2wPBg8+EFyEuLeIbH3rrbcsR0TjIryJcEZgEE3M/CmDGAIrV8RHz8DMvBkfOEKUNeC4hxHkfOwuCpqPn4HbCc8gHyxbI2qfwQyB7HfbZ8Mv0bYkxmHAYGkMygVuSQZktxwI4YeyQNQu7l83d+qfl8Z9y7ww9wQJoQUFlwUF7wN/FCjmFRnoiBBmqoH4Ba5B4MHAixKDaxdXJuW72APuQVnCvek/3CCOO5Xz6VyolEG0snPNogwQ9c+gDC8oe7hAcYnShxBmTqFAuNGujrgXpRHBGyTajncNrhX334e7GEWJ/kEduHNx09JuvDdCA0UJocMUDclHEC60ZzBugDaF3PJEfz2cczETQT7db4QLChXuYlYf4KpHuaGdeGf6LkKN/1n9QPu4+IJUsSd8Cyi1zGGXhohDABfiCxDYfK9gwaoRFEL6DX2GaQbm9HHJu2V1QVxQiFwf9fPAO6KcOWGaij+W58ELSgTCmDZgHp6odq7xPfMNUQffGu54N3cfjClgLAJP7sWVj0JP/fQ1vh+31C4VL3o+egRUoEePuVcj85XM1fkJYYWGzoDpAquCgxsWY64IK4JB3r9mFYvaDcQITMeHS3RB3VirwXlR5jN5liU2LtinNHwST8AyML+VyMCBle4EDdYegtNv9SP0/euMwQ/+GVSDgyPz6FCmdeAoE/4lPDxDEg2EKG1DuViRwbbBa+APMGS+HuvUfzA/DKEocN4fI2AvBIilZ+IKTpoPZ2AlYAnBgEBHEPDbTwgP/xw6GKK8sXbeTyxXwoJFQUo3b4xQQZnAQvcTAz1E+S4wMbjciWVpfkIpRODAD7w7QuBgERLDkI7ofyg6KMV+cgluEEB+ZcbdQ12pstC5PAziKk9XdYlrWLcIcRQbP7n8DCjsDhf6rp8X2tZP9Ft49K9n5zrfJwpBJiUZAwFeXBCoK5s2om2p3/VPPy9gRTImPzE24G3ze7PgAcODYN2yfONJFeiPnCOgAj3nkGZfIFYDH3Tv3r2tywvLBk2aQZggG7R9PjoEJBYJghUBgGXCx4kl47cGs6/5vzuJuqUsXLZYpFgUaPAIHQQNAt1ZU0T/8uHDJ9YZFg0Eb/CMgGdQ51l4DB5o9umIICgsFrwDDGDUQ1AOQtJlwcMV6vLD4/ZHQOPWxPriN65BCGGJkEdpgj8sULJv4S4nuCyTEKVtGBzxWDCgcRCYRDvRNk7pYfoDaxDrBuGCBwMlBMEUtHjSvXu6a0wTYOWheKH0MD2DCxYPCX8RYigoTlijyLCOmvwFCBMsapKEELcR8o4AACAASURBVMiG94T1z0wnIMRx0WPdIkT8WfXC+EGJ4F7n6ocnrDimI7hGX8INS1tgJdI/wB5lxCkBTBk4qxQvCm2M2562QoDwrngCMqUW5V0QfkTFY4ET6Ebb4kpGyWG9Nh4Q2gmlGQGHlYz1Dd8QFrx/NYLL9ucP8AvDIXgOBYB+T1+hP6IgoXTT3/CoINidCx8lhOkI2gSPiqsTpRRhSd+nPRHKjA184ygaKLr0q0yBlbQvihf9HgUDXhDATFVhUSOEXQ52lFa+GbDhe3FpgekrfM8oo4wNBMWhkNDfZCmbnWLhnFIBIiCWRqzr5qgfWhOD4mSwS7BOVrqFdxDk4l/PKsIx6TrBSDKgewFSwSAZwbNU69C5362n9vNBEJIMsFy2a+AJsvJfZ22sC9ThPGvc/UFz/nvd//51tGFBcTKIJMQdmVQPz0rUr107C8nAX6IeGcQTLpjJrZEmuEsETImyRBAkRLjbshyFBcVRnwsS8r8La1ZdEJsM2nadrrsuQi0hAiYhc8j2HGu2w8itAxZBU+JyWFAc9YkwT3oXGZgTBDY5EmUsQdCe40WS+CTEykuIILDn+AvR52TZXYmyCHoMUlhQHMFbBMH5MSHoTOZqvcfd2mp3D2v8RclIiEVun3P3yjefkHndpLK4HoZLWFCcKHY2GNLPi0xfJETJ8HhhDb7/OoGT5HhwwY5g5IjgL87LcBSEIul3WFCcKFpJgYLUSdAba9ohyiQfg58X8CWfgghNe94F4rHG3QXyufsJ6PMHyzqGwoLiWNvvynTPg4vLPyFKeUKmgpJ4IdCWwE13vwh6WwX5EzhH33Z9PWzM0aC4wgiK02Vr0lvjItxgaOrMZWGpMJfFkhX/3BSWM9o9QT9o18y/YZ0Q6II1gMUUJNxhWCyZ3MruObRtysEyx3rC7Y8F7lxyzNujxZOljvlCrFuWTWGJYZWi5XMvFmI68i+dCbsPK4+5YlzdWE/MGbLWG8vdudixvMCM+WusBqwI1qRj1eHCdTtjgRWWKhjBO+8FHgRs+df0h/HBOdzqWJ+4igmuw4VMPX68sWqYn8Qak7HPLlXCusOCId4B3sMI3mgffyBf2H3uHBYXVhYWH++ONUjZ/ikQ6sPKAzesKiw1lhVhNWPdOezpc8wTUz/WG1MG9JdsdxTDAseCw3rEa8E0BJj488pjqeIFwSND0B99ifKxkFmyRR+H4BN86Teuvd0yuHR4uGtggBcATwOeGWIRXJyJuwevEpYwuHEdTw/9jN+8vz+fAZ4wrvmnc7Lhg3v4Hoj7IN6E7wG8WULnpoooEw8W70o7cZ2gUqxuPFB8V64/ELQHftzLeQII6bcutW4mnrCi+WbwHvGN4MmgrzoXOd8tfZs+hQcFNz64870R2EcsgJsyYfkb7UW74Z3DGxbHLoGZ3lmvr0SgCOUxbjAYDHH5cTAPyMEcmXTKIueSkkxxpvEhzVKyShmFSrWqb2ceFre6i7COi08GGtKvMqBnmovLN48M5AxouKXjXs+Kq5mpjFTBUvnGwl8+kchEQIcFrkXJB3XRRzhSzTlHyY9L14pSEzehvDJNli5aPioeUUBQnDLFHOSbHxQDFCbJFCfKW/jGTvnmoTTlt2/Z1EydPMk+wjiEsoTXC6WHgzGJ6Ub3l3MYAhwoREyLoABxoJjSDmVVBkvDd6Z7dQ49E0J6XRFQBBQBRUARqAAIqECvAI2kLCoCioAioAgoApkQUIGeCSG9rggoAoqAIqAIVAAEVKBXgEZSFhUBRUARUAQUgUwIqEDPhJBeVwQUAUVAEVAEKgACKtArQCMpi4qAIqAIKAKKQCYEVKBnQigH1ytX3sRL/ZiD4spcBFnlWGLh0lCWuaAcPOhSkhYCLyyXJN1sMHVqDl6z1EXASyFgAuPwUghL+eBlhWQu86fULTWwOXoATKBCaCPwIEdBIfBCGmSWbVXeuHKOkNZiyoKAJpYpC2qlfKZ9py42KQhrF91GCKUsoty3I7BI+bm5JPogrSa7t/lzOZe7glIUwEBEys4qsiaejUpIU5lNspdSVJH1raThJJnN+utvYHkhDSmDZBxEEhHymJPAg01uXOrNOHghVwEbn5AEhbYi2VFZEq6Ul3cEKElNfpGd5NgohIQsce3yhcJHEijJI2dTEvP9kFgnDqKPkOp2Y0mAdKmk8SUtq38f+Ch5IpcECWiatWxlKsn6baX4EFCBHgH2V153g7V2rr76GrPk1yUR1FiyCpIh1GtwsBk0Yox55MEHzHmSRzu4W1rJp/JzhmQNzVu2Nr2ffNbcfnMvc6rsOEamtzhos003M126H266H36EufHaq8xxsnVtXJZ61apbmQsuvdwccFBdc8sN15qnZXOVuBImbb/9DuZ/jzxuNpBEGvffdYe586674mgeq0Tssutu5pV+A82Xn39mHnyot+Q3X5mvP2qG8G7ttfc+ZsCwUWbksKHmhht7SS74n6Nmw9aH0lmnbn0zaORY8/Tjj5qLRQEM7twWFWMo402aNje33HlPVFVqPSkQ0ExxKYAp1NO4qhlYCoEKhZdC4YM2UV5K9kzFRDEpiUC8ZzRTXLz4a+2rEHjhmadis9r8jYDH4eXnny2Idhk6aID5UfKnFwLRPoVAn83+1Lwz7a1CYMUUCiZ4gV7r83JBYAIfyySmpRCoUNqnELCo6DxoUFwFa8Gnn3jMfPrxR7FzPeu9d80Lzz4dOx8wMHTQQDN+7OjYefldYgNuufH6pD3I42Jq1PBhZtjgQXFVn1TvA/fcZb779pvYeZn65iTzep9XYucDBga88bqZPGlC7LwwfXHvnbfFzocykBsEVKDnBsdISsEK/fD9WWakDNZx04ihQ8w7stMYwUpxEnPMI4YOtgNk3DRx/FizeNFC896Md+JmxfR77VUzaEC/2PmYN3eOmTvnKzNm1MjYeRkycICZNGFcbPEaDgA2npogCuiQAf1jx2TsyBHmG9mj/vPPZsfOizJQfgRUoJcfw8hKePXlF2yQEEEwcdPzzzwpvGBppN8yNd98znx3hg3uGzNyuA08jJMef6S3rT7u9lkqeKD4YRXHFUDm2uG5p+gnRebx3g/G2TS2bqxz5vNHDhsSKy/jRo+0u0n2e71vrHxQ+WMPP2Tb5/mnn4ydF2Wg/AioQC8/hpGVMKh/Pyu0vp//nflN9jmOi7DKF8tyL3iJ2wocLta523L3/ZnvxQWJrfed6dPs37EyYMdJWKG0DWu3scDipKGDB9qYDyzA5cuXx8bKN1/Pk616f7cCfYjEXMRJTBHBx7Kly8xXX34RGyvw8KnsbU/7DB8yODY+tOLcIaACPXdY5rUkPr4PZs20dawlUe6TJ47Pa33pCh8zaoQpkiQSEIFXcS2tov7Bq9yWCDCEe1z0yUcfmmJpI2jJL7+YReJ6j4vAxHorZKCO0wr8S3If4G6HWJkx/a0pcUFiRo8Y7tU9YeyY2Pig4tGrlKxEotgQ6xAX8e2utZa42YRQeP6U9eRKFRsBFegVpP3efedtK8ihf8TSGdj/jdg4Z756hbgMIYT5Rx+8HwsveCnmrRIY8DGwX3zz6COHD/WC4XBhjhs9KhZMqBReHE19c7J178ZBBH25JD1Y50MHDoyDDVsnMQUoxdAfv/9umNuPg/CuubXrKF39Y3S7DxsyyOsbtFOcRkIcbbE61qkCPQ+tymBxwlFHWEstV0TgF9mhHKHZx2EZMwhNGj/W44OBekRMc5LjxowSgbGex8s38+aZn3/6KVeQl6qc/q/19RLSsDwqrtgClqv9tey/frKeDNTvvj29VO+Sq5sJQnNLs+ircbm6aY93fYGK9OGxMQXp4SlYi+CTVfTBrFmxLV8bJEaB9eQIkUmSKT2lio2ACvQ8tB9BSViLG228cc5KH9jvDfOvpJ50xP+zP/k4Z+VnWxDL1Zy7nWew/uISXmDCvKijddZZxyDkoyYsvmCU8OQJ42NZvoait2LFfxY5AYNxLV8bLhagX+lE2Ypj+RrL1Ui77AjFGIs9Duonih97Kjhaf/31zJuTJ0bOysKFC8zCBQu8emknv2cncoa0wpwgoAI9JzAmF7J7rT3MdpI6k2VMuSCWq83/7rukov62lvF/rtVc1JNNGSxXQ5v301dffBH58jUGIIS3X2CQ+jIO5WLCuDEiMNZPwmRtUS7iWL6Gp8DvySFgMI7ARbxUYamF41i+RhBacH6Ytok63TDK7zvTk5P9sK/B4Bgs4zHiKQhmnASPoGKazZig9xQOAirQ89AW7Dp06plnmTNPOsHcddvNVvNl0PcfwQEmHRsEoWF9+mk5bt0Y5t8GiOeBOXw/rSvWT66Ul3Q4+K8xb+/chZx3G4dMHDc28uVruC5///23JNbx0mChRknU+cnHH9oq/RupLJTkIVEvX0Pxc0GCDoOlS/80/fpGbxkPk0h7N3/ueFlXFDAs9yiJoED/FBF1o5AOF6yipv6y3JRNVfyEwkGOeqWKi4AK9Dy0HfPK1191hVm8eJFssnGdOaJrJ9O1XeukozRBOQNe5+P73W6UAblAI+ZLcfdGRbhMiYaF1lm1I9mGG1YyZEiLOiAN7wQWxQYbbGD5wSLG4igqWsswLRAljR4xwg7MKDbQ+sITljFTAlESy9XWk014UP4IoESxBJ+11lo78uVruJbx5Lj2cX2WpX1RLl+jv7K1JwqO12crVZLv5jdJ7BLt8rVhgwYlfcfwA1/LRNGJcvkaffMtCZaEXLtssMGG5m+ZisDDo1RxEVCBnoe2Y2ezWbO/THvsVrNWVjVjWUySJWoIiWYtWtpnWrRuYzaW+XmuRWkZ4+JmMGDLxmbNV/LSuGlT2Xp0fVl7nez+zurlynET3ol/V/xr9tlvf1vKnnvuZbeGRfGJ0sogDS+u/kqVNjKdu3azvHTq0s2wo9zcOXOsUhcVDZYgNJSrbapVM9tsU80qgDV23kVc8MsiXb7GcrWZ775jt8Rt076jff32HbtYTFb8uyLS5WtjZIkYih9bndar39DyUrd+A6sAEuUdJQ0e2N8qWXXq1rPV1qlTz2y66aZW8Yly+doMlCqxxumzHTp3tby069hRflcyH7w/s8T0RJQYaV3lQ0AFevnwC30arbt6jZ3THv4gndBCVp1kuRqu1G49DjcXXnqFPbu1DNavDx5utfsol6/1F0/B2jIg9R860mxZpYrl5ZobbjI9eh5pE91EtXyNumZ/+ok5qG5d82r/lYMyCs/4qW+bLbbcUjCJbvkaEf7/ipC658HeZr/aB1hMWrZpa2649Q5x/UtilwijqUfJ1E412Z97zJvTVnkriszICW8aYjpYvhbVtrAsV8N9e8Ipp5ljTzzJYrJTjRrmuT6yl7hEVUe5fO2Nvn1sQNxA2Ta4sgh16IHej5q27TuYH76fH9nyNZarffvNN+aQZi3Mw08+Y/kgaHbUpKn2b5TL11BkUIYff/YFuzUtdMRRx9jxhT6iy9csJBWSVKDnudkIUPp63lw7cPiPbN2OCIQTTz3dPCKDgH9etH7Dg+2+zDNnzMjzG6wsnoH4448+MENGjzd16tX36oSnhx57yhx93AmSMOO/5B35ZApPQeNDmtlBGlehox123MmMlgGS+ISolq+NHzPGPPr0c+bIY45LeuVTzzjL3HT7XUkJTfKJCcFMm2++hZkwbYa1zh1tIhbgyPGTTS0R6lHtvjZ25EhzwSWXmdvuvi/plVuKZ6nPGwPN1Ckr3b35xIOyscxxuY+eOMXsf8CBXnVMRzzz0qumc7fukjI4mkx6LFfr0Kmz3dfdHw+zu3jqRonS9f38+ZEtX5syaZJ5se8bpmOXlda5A+bSq64xl1xxlRnlS8KT7zbS8nOLgAr03OLplfblF5+bVk0ammqbbWT2q7mL2b/WrknHFzIAZ0M1dt7Z3Pvgw0nC3D3XsHET88DDj1mFId/EHN8Tz76YJMxdnVaoP/6U2Xa77fPNhi0f5aKPWOZuftZfKS7mQSPHms8lviDfxBrrk08/w1o3YXTuhReb1u3aRxKk9+03X5shY8abrbbaugQrCHWUH5fQpMQNOT6xX+3a5oZbbg8ttVXbdubaXjdHMhVBH3hFFIi9992vBC8I1adffMWATRRUSaYbnn2lrzdn7a+zlkwXvT5oqPU65ZtI23zpVVeb9qJchNE1N97sTQmEXddzhY1Acuh0YfNaYbgjQOqYw7tb92//YSNtMNyA4aMkq9kc2arwdnPoYUd4rq5ML9UzYPkF70eoR0G77V4zbTUI9Z5HH5v2nlxdBL90hFDnyDdtKHOOXQ7tkbaaVMI+7UNluNiiVZu0TyG42nfqkvaeXF088tjj0xbVqk27tNdzddHFV6QqD6F++JFHp7qc0/OH9TwqbXkI9SiIOJO2HTqlrSpT+6V9WC/GioAK9DzAzzIhkr58OvdbCVDa1tZwwIF1TFMJJGveqrVpUu9Ac8a555ltVkWt54EFLVIRUAQUAUVgDUNAXe55aPAFP/xgA3CqbbuddZXjbvvtt5W7o+24U3Wz8y67estG8lC9FqkIKAKKgCKwBiKgAj0Pjc6yIdaHuzzWO0qw1vS3ptqaCNT5XrK+ufWfeahei1QEFAFFQBFYAxFQgZ6HRsfNzhwuGd6go48/wVx4zpnmzFNOtIFyf/39l2nYKJq57zy8nhapCCgCioAiUIAI6Bx6nhrljSHDbcIV6JwLLrZLVcgoRnBZb4kIJ2BOSRFQBBQBRUARyBUCKtBzhWSgHH+UNfPoZ557gT2UFAFFQBFQBBSBfCCgLvd8oKplKgKKgCKgCCgCESOgFnqOACdFa/dO2a+vHTFukolq7WmOXlGLUQQUAUVAEShgBFSg56hxtt1uO5vuMluqUnWrbG/V+xQBRUARUAQUgYwIqEDPCFF2N7Dm/IJLLs/uZr1LEVAEFAFFQBHIMQI6h55jQLU4RUARUAQUAUUgDgTUQs8R6myscMVFF9g15+T3PrzLyn2gUxV//8OP2u1VlRQBRUARUAQUgVwgoAI9FyhKGaw5ry47o2262WY23Sv/pyO3Rj3dPXpNEVAEFAFFQBHIFgEV6NkileE+1p3f3/tR7y7//xke1cuKgCKgCCgCikC5EdA59HJDqAUoAoqAIqAIKALxI6AWep7aYPny5abvyy+at6dPM7/9unKnNX9VN91+p9lBNm1RUgQUAUVAEVAEcoGACvRcoBgoI5FImKO6dzUTx481dRs0NFV1zXkeUNYiFQFFQBFQBPwIqEDPQ3+YN3eO3Wlt5IQ3TT0R6EqKgCKgCCgCikC+EdA59Dwg/Pdff9nd1Q6qWy8PpWuRioAioAgoAopASQRUoJfEpNxnau6xp9mtZi0zbsyocpelBSgCioAioAgoAtkgoC73bFAq5T2sQ3/ljQHmpGOONGNHjTK716xp1lorWXci+czmW2xRypL1dkVAEVAEFAFFIBwBFejhuJT77MB+r5sPZs007814J7SsOvXqq0APRUZPKgKKgCKgCJQFAXW5lwW1DM8sXLjA3HTdNXazlnkLfjJL/i4ucey1z74ZStHLioAioAgoAopA9giohZ49Vlnf+cP8+fbeK6693gbHKSkCioAioAgoAvlGQC30PCC82+41zQYbbmi+/ebrPJSuRSoCioAioAgoAiURUIFeEpNyn6m00UbmtrvuNacef4yZMmmi+XHxYrPkl1+Sjn///bfc9WgBioAioAgoAoqAQ0D9wXnoC3///bc594xTbckdWjULrWHKjFlG59FDodGTioAioAgoAmVAQAV6GUDL9Mi6665rnn351bS3aR73tPDoRUVAEVAEFIFSIqACvZSAZXP72muvbbp2PyybW/UeRUARUAQUAUUgJwjoHHpOYNRCFAFFQBFQBBSBeBFQgZ4j/N99521TfZstTe8H7jXMofN/umP2Jx/nqGYtRhFQBBQBRUARMEZd7jnqBTvstJO54ebbzAEH1bFrz/k/HW29TbV0l/WaIqAIKAKKgCJQKgRUoJcKrtQ3b7XV1uaEU07zbvD/n/opvaIIKAKKgCKgCOQGARXoucExbSn//POPzeu+dOmfZt/9aptNN9ss7f16URFQBBQBRUARKC0COodeWsTS3D+o/xvmvDNPM4lEwrvrpx9/NM0a1jUtGtU3nVq3MDWrb2cGD+iXppTkSz98vzKNbKoHli9fbhPX5JsWL15kVqxYkbaaTLymfbgUF7OpJ5t7SlFl6K3Lli61yYLSEXn9i4uL092Sk2vZvG829+SCmUz1ZINbLvhYsOCHjNhn4jUXfFBGpnoYM+A33/Tbr7+aP//4I201C374Pu11vVi4CKhAz2HbvPz8c3abVLZPdXT91VeYzz79xNx+z32m78Ahpl79huayC8+3gXPZ0L133G5mvfdu6K0I89NOONZssMEGoddzeXLddda1me/wNoQRHohHH3ow7FLOz/V77VUzbPDAlOX2uvZqs2jhwpTXc3Vhw0qVzFmnnmR+/umn0CIR5jdec1WJrXNDby7nyQ/en2XuuePWlKW89NwzZuL4cSmv5/LCLTdebz6b/WlokQjzU6XPbrTxxqHXc3nyX1FASfCUSqGaNnWKee7pJ3NZZcqynn/mKcF/bOh1hPmlF5xrlv75Z+j1XJ4E91PkO/7j999DiyVd9R233BR6TU8WPgIq0HPYRp9K5HqDgxt5JSL8sMaPOeEkc8Y555vWbdubp1542fz042IzM8W2qkF26tSvbzq3aWk+/vCDpEsI8x6d21vNf+PKlYOP5fz3ZptvbuZ8+YU5qkfXEpY6Ckf7FoeYA+vUyXm9YQU2bd7SHNfzMDN8yOASly+78Dzz7FOPm333r13iWj5ObLHllqZNs0YlLHWsnGYN6pjtd9ghH9WWKLPJIc3MHTf3MvfddUeJawgTBFuzlq1KXMvHif1q1zbtmx9ivpL+4ieEecfWzc3y5X8bki/lm7bbfgfz1puTRIAdXUKov/XmZNO1feuk7zWf/DRu0tQc3qWjmTxxfFI1CPMzTz7BjBg6xOy8y675ZMGWTY6Mtddey2awDFrq8+bOsd5E9qJQqpgIqEDPYbstWfKL2Wrrrb0SP/rgffPrkiWmTbv23rkqVasassTNn/9dVjU3b9na/P77b6ZtsyZmzldf2mewOA7r3MFMnjDedOjcJatycnFTu06dzZiRI8yRh3b2phWwxDq0bCbxAUsNgjYK2nPvfayFd+wR3c3I4UO9Ki8Xz8cTj/Q2jQ9pmuQlySdP7Tt2Ml9+/rlp2biBWbZsma1qibR584PribL1vVXioiC8BSgxva69Kkmov/DM0+aCs043O9WoYbbeepsoWDGt2rQzP/30o2nVuKHFAFqx4h/TqU0L854osh07d42EDyppJfj3f62vOeW4o70+Cw8I82LZT6F+w/8U8HwyVad+A9snu3dsZ6a/NdWrCmH+6ssvmpat2+Sz+qSywR+PWjtRwv8RwwBaJN4k+jDTd63atouMF60otwioQM8hngyYc75cKXQpdsrkidbdelDd+km1oBlna6GgAOyy2+5WqF94zpm2HITq29OmGjaBad2uQw7fIH1Rbdt3NBtvXFnea7KZNGGl+/Z8iRn4888/zF4iZDfZdNP0BeToKgMjQoM5/XNOO9mWiqvwxeefMZVEsHU5tEeOaspcDErM+utvYL6eN9c8/vBD9oE7b+llXf4bbbSxXcYYFXU77HCz3nrrm7tvv8X8+usSs0I8RFdcfL4VJJ27do+KDVO9xs6GZZkouFdefKGtt58IVbxM7ELYIkLh1V6UUDxYI4cNMR/MfM/yctYpJ9opr3oNGkrbrR8JLnzvDQ5uLN6J5XaaBvrk4w/NoP79rHLaqduhkfBBJS3atDXryzTdbJkKfOWl52291155uZ06YrxRCz2ypsh5RSrQcwhpsxatzP1332mmTp5kSDTz+MO9Tb2GB9uPxBEaMMEvO+5UPeuau4qAWkcGBFyW0OJFC601uL4M3rX22DPrcsp7o3VjS3gA0fqLFy2yxf0p837rrbee6RJxqtvOMgBW3mQTWz+0aOEi60L8999iQztERShVtfbYw8YWuAA5/qJsNG7aNJL5c/eueAPWXXcdiwPBTwgP8EFgtBNPQpSEIIVQ9qAfJaiSPlulSlWDKzwqQoii2IDDIvluILxJeDS69Tg8KjZsPYeKwoWS5+bKFy5YYL+lFf+sMAc3ahIZL1WrbmW23XY7s1yUml9+/tnWS3/B/d9GlHaliouACvQctt3FV15lhVv7lk1tVDsWys2335VUw4vPPW2Yd91nv/2zrrlth47W8nTR8wgLa6W2i9Y1hrfBCUt/xDvaftv20XkKAA7LGIHlqLh45Xa01Xfe2Wy+xRZZY5uLG7sddoS1eNyWuEyJYBVGnc8fy2qDDSvZV6KvuP5CcNhBdevl4lWzLqNjl66msmDg77PM30bpbodZvkf37v4ti+33E7FruaVYxonEfyseHD/71T7Aei6ipC6HdrdGgvuOaadNREHu1LVblGxoXTlGQAV6DgElucyUd983g0eNNc/3ec3M+Gi2BIrVTaqBweWFPq/b4JRsCbdtMFK3cuVNTJdu0blRHa8MBNTtp7WK1op8K1jc+7vJVISfcGvizYiaiJFYLxDkhRBt3qp11KxYxcq/ygIGDm58iM1eGCVRZ3AlB9M1CPqoCUu8UqWNkqrdXII8o97xsJpYxVXEOvYTghzLPWrCEsdI8BPtRfCeUsVFQAV6jtuOJWSNJeK4swhbBHyQGskHc3CTQ4Kn0/7GMm7SNHlfdazTJk2bp30uHxdbtGoj7uX/LGPqaNmmTQkhko+6g2WunDNezzvN4Ig3I2qqtedeZl2xBP20/Q47GlybUVNHsbCYinCEu71bj+h3/uM72P+AA5Nef7n0m7oybx01tcF79N9KUjsN0r5TdMGk/vfFAvYr8+usvU7kngL4qVOvvudRcvztve9+kSwnjLr9vUqnDAAAIABJREFU16T6VKBXkNYm0It5P0e19twzkuVqQXhYvraTBD05Yk4wyiA0Pz9tJCAwKahJ8vlEtVwtiAtBes4yXku8L3gy4qBDRMnzW8bFxBTE4Cng3Q9lKsIXdEYQWrbBoLnEjjl7LHJH9Nk4PAXU375jZxvM6vGy8UaRLFcL4olS0bBRY+807RJ1TEGQJ/1dfgRUoJcfw0hKaNm6radR8zHG4aZzL9q1ew8v2IvlSIc0axEJBsFK9tpnX+Hjv6mLpi1aRhqE5ueHIL31Vgmv9cVab9sh2iA0xwtK396Ci6Nttq1mtolpI6CVlvFK0xiBcWjEQWj+9ukgS7WcwoWnIKrlasE+S5CsS84EP+1i6ifwRXsQYwCtLVMyrX3La4N86++KgYAK9IrRTmbLKlU8Fz4uwyiXqwUhYvmacxsyDxlXbnoGxKbNVyoT8BOHa9lhQ5Ae8+YQAUa1DzwoCFtkvw89/AhPeHXqEt1yqOAL7lS9htlwVbAXyZDjiClwPJGvAaEF7SOu5aiWqwUxIZbhgANW9g0bJBhjEFpzWT7oYnPWW3c9Xa4WbKwK+FsFegVqtMar5tER6FEuVwtCRFSuo6iyjwV5cL87rAqyQohGldgmjBfmqquuipnYvdYepQp6DCuvPOdcMhsUHrd8rDzlledZ5mohBDtxBXERy9cSq3Lqo5DGSe06rfTeIEyjXK4WfGfyZhCoCB1wUHwKaJAv/V12BFSglx27yJ884eRTbZ24D+MkFArmjCHS2sZJDM643XeViHeWA8ZJp5y+MvHP6WefGycb1tICCwLTol6uFnzxU88425464qhjgpci/Y1rua5ka4N69Dwy0rqDlRFbgLLF6hV/XEzwvih+H33c8baaU85c2U5R1Kl15A8BFej5wzbnJWPtsFyru7hU46buR/Q0W25ZRbaDzX49fT54Bo+99923IAJ6cOsWyRI+gvXiJqL9WVER9XK14Hs3adbcZtIj7iJuOqznUTahE5ns4iSC9MiX0OOIeBULMOgkq3FQdppHmIwpTuxX97qjXZy6uqOZ5/fDMu7YpVtsQWj+12P5WmeJ5A6uec4zBKHFM3ceZXa4UCbkJMvXiG73ZwZMdW++z3fqeqj5JcUucPmu218+XgIiyus1ODjKakPrIkhvzldfhV6L+mSXbj0KIggNI4G+4o+8jxoLrS93CKhAzx2WkZR02VXXxLJcLfhyLF87/+JLg6dj+d398J6xzs/6X/qGW26LBYNgpey+9seqtKvBa1H/vrbXzbEsVwu+J5bxKWesnBYJXov69wmnnBq7p4B3JjCP9lFaPRBQgR5RO87/7lszbvQouwtVHMRcHXuxk+zji88/M5Nkb2w2fImDyDSHK5a5XrZenS4bzbg89VHzw7QB0dcM9lMmTTSzZr6bcs/3fPNGJjGWJ5K6dvTI4eZz2cnOn6403/X7y8ctzdRBkXiFRsmOdnPnfOWlcY2SD7xS9BN2TSNH/agRwwzfUhzE0juSr7BMk/0YxsomSYslR30ctDI+or6NkaBtJowdYzfkiYMIrDu4cROzx157x1G91ulDoEiig/9LLhwTNEQoE/HJQW5hDtZqtmzZsmjmzJmWqyGjx9kMbKnI5YxOdT3O89OmvGn3Lt92u+0kqnTjWFgB09mffmrnMge88brZvWZNbw1q1AyR+OQL2XIUV3n/118ze0iSnNKkws0lv3+IkPh+/nzTVOYQx40eaWrWqhXbNMJPP/5olv31lxVgbL27y6675vJVS1UW255WkgQszK/+9OPiyPZ1D2Ny3ty5gsVudsvhtUXAV90q+gx8jq/PZs+2qXRRQqvIUtJNI9phMIgLih7fcyeZghsyaIAkp9nFBkHGQYzV8HLfQ4/EHiSb7fuz3wabaEHdu3c3NWU8lFS4CdLhcmwkyX8Yq91fzrFSg4Mlj3wXxKdwMHaheHLEPQWpFnq2PaAc991y43XmhBNOMA8++GA5Sin/o4MGDTJHHHGEueOOO8wFF1xQ/gLLUQI8XHXVVWbAgAGm06plPOUorlyPHnPMMebll182H3zwgdl77/isDBTaBg0amPdFif3ii88lIUw0+5eHgfeXKBYoFMX/rjBz5syxA1tc9JPEAuy0007mIFlaNWbMmFgD/b744guzrwRh8h09++yzcUFi6x0/frzp0KGD/Y6uvfbaWHl58sknzWWXX2aOPv7E2IVarEDEXLlGuUfQAF/K4NysWWrvQgQs2CoaNmxoGKgLgZfdd9/demQKgZcdd9zRbLbZZrEKc9oHDb9atWqy6cyusQpzeMHa20LiJOrXrx+rMIeXLWUJHqsZDjkk+k1mqN9Pu+22m40HaN68efBS5L+bNm1q0/wWwjfUokULuxXrj+LNUYoPARXoEWDPdEDcrhj/axYCL26KpJB4iaArZKyikPoKbYOSUQjk21ulENgpiO+Z9imU/uK+4+CukAXRWGsQE4Xxta5BgOurKgKKgCKgCCgC+UBABXo+UNUyFQFFQBFQBBSBiBFQgR4x4FqdIqAIKAKKgCKQDwRUoOcDVS1TEVAEFAFFQBGIGAEV6BEDrtUpAoqAIqAIKAL5QEAFej5QzWGZQ4cONf369St1ib/++mvOMp79LMtRHn/8cVkb/UWp+Pjll19ynunsnXfesevoSQiTLcH/fEkek+sI3DfffNM888wz2bKRdN/vv/9uli1bVqZnwx56+umnzWWXXRZ2KfJz8NK3b99S1QseCxYsKNUz2dx8+umnm9dffz2bW/N6z9KlS22/nT59etb1sCTt66+/tktNc0mLFi2yvHz88cdZFwv/3333nU36pVS4CKhAL9y2sZzdf//95uabS5drGQFGFqvBgwfn5O34kBkYp02blrE8Bp9LL73UruveQlKYbi5rmS+88EK7XjYXNHnyZHPFFVdI2trfMxY3a9YsU7duXbuOefvttzfbbruteeSRRzI+l+0NJKM577zzsr3du49ELVtJtrMbbrih1M+meoAkIy+++GKqy955MoyR5YplRsHj7rvvzvh8Njc88MAD5qmnnsrmVoNwIbEQGddYg7+nZA2cMmVKVs9mcxOKaCYhSpIl+mqqY4cddsimqrT3/Pnnn7bfTpgwIe19XCTzGt8M30716tXtt3TyyScbysgF/fDDD5YXl4UzXZkYBiReggdwoI169+6d7hG9FiMCmikuRvDzVTVZm+LSpMmI9+qrr1pBWkvSqDI4o5T8KGlNX3jhhXy9colyUWratm1r8BIcddRRNo0jWenOOussU7lyZTtIxUUM1rm2urJ9FwZzBMZ2koaYFJZ+YtCOkpYvX27b6P333zfdunWzSk6fPn1M+/btzYcffmhI+BM3/fZb9PsdIGz5ZurVq2fq1Klj3nrrLYPXA4EOPlERa9wPP/xwM2rUKNOoUSOz11572Ux955xzjtlkk03MscceGxUrWk+WCKhAzxKoQr8NF/TIkSNtOsgnnngiFnZx4SHMjzvuOJsWEwsQwdWmTRvz0ksvmauvvtoK+SiI+hYuXGj5YVCCrrvuOjso3XPPPbEJ9OHDh5thw4ZFAUFoHbhwoYkTJ5pdJP93nIQVj5WI8Dr//PMtKyiEZKd77LHHzC233BIJe9TPESSmmPbZZx9z+eWXBy/l7TfKFl6kVq1a2e+Zb4ipoi5duthpjDvvvDMyRYexBGGOd4AxBV5QcFA0+JZRlOPagyFvDVDBC1aBHnMDogUzT/7ee+9ZKxLrJEzo8VG/9tpr1prhOrmk/RbWp7I5Qo8ePcr8Nlhu5HpnrpmNCigraMFROO53XLu40Dt37mxq167t1cnzEC53lzmKFKIXX3yxmTRpkhUiYe8WZBqLBEsAi4TBo2vXrqGZuSgPqxvXJEoE7klHU6eu3DzDjwlWKQPlwIEDs86wBd94GciYRopNPA9hxODLdAB1MNCFbdoBZgiu0047zTz88MNhxaQ8x3z7//73P+s+JvVo69atzYknnlgikxsK1G233Wbvw8K95JJLDGl2HX377bd2EC6PGxmh88orr1grmukMhM0ee+xRgnd4QWh/LhvxkP8ciw53vyOuwQcWnyPam7Sq38vmMNkQCsqjjz5q4zso69RTT7Vu+yAxzYEixzw9KWTPPPPMjFu6nn322ba/0n+zIaYPsKDnzZtnatSoYZVG+maQ+NbwouFFateunW1LR/BJW/NtuW+IvtezZ08zZMgQ88knn2Ql0MGF2AG+Z94BXthgJEjUh/VP38RLQnpoRyifEMLb8YJljpeLqSbiWVC+lAoHARXoMbYF85nMH7oPB1auvPJK8/zzz1uB7aeTTjrJPPfcc94pBAJCz+3ehhAePXq0vY4Quummm5KeT/cDgQUfuKcd3X777QahiHvaEQPzRRddZN3nEHVgTTCIQgweCJvg4M78NcR8XCa69dZbzTXXXJO0VeeRRx5pN0/xE8Fo/vuY/8WacAMMAw/KUTB1KQoUiooboNLxc+6555qHHnrIu4Vn4A+XqJ+wJOHF0V133eUJd/999913nx3Eb7zxxlIJdARokyZNzIwZM6yrk8EXa43f/pgA3u2www6zCiK7QhHIhIeCdsQzAX3zzTdW6fAL1qSXyfADJatx48ZJ86/EAqBs+jfZYcqnY8eOZuzYsV6J9F/aCCWPvoZ1DsZBK8//TDp2UG5xBeOdokwUCL4L5qnZ5MYRSgy/Fy9emWecIFMUMBTQYN3uGd6H7wvlkh21MhG8kM+cjWQcOcXKrzyhELPJjFNY8AzQn7gXclMxwW/F/aZdM9G4ceOskuUPHOX7QAD7Fc2PPvrI4r9kycptV1F44MfFhaCYUJ9fUaZup5RjhKhAz9Qa0V7XoLho8U6qDbf0iBEjDB8bFgZR0whDLAPmFx3x4THIMVAzCJ5xxhnWAkMwOGKgl+1m7YGbsDREeezshSIAH+wKh/s8GCRFZCy7O2GZwYuzrvjwISywN954o8QgifcAymQVzpVtMq+//npz9NFHG/7HyoA3rEEGKT+hTBDwRN3MzaMc4a51+4fjsvUrQDxLmQgUNrXIRFjbCHMs6tmyZSaDF9jitkdAOEJoghM80E69evWyPNGGfmIgR/DTZgRflYaw+hDeWFwM7BxY57yjc6FTHtYn7ffll19a1yht4bwCrj54R6ATaIl3ZVfZUY2AR6zGbAilhPd0UxoESmKN+q1sysF7wpQHApH2P+WUU6yS4/oU5/A6HXjggbYvgxftxzeRbfwHu4wR/Mk7Y9VivVatWtValH5CqcESBjd4on8x7UG/CiP4ogwsZzwG2RCBdSi/fMPUgdKAoKQ/+wkFDIUI5RhsmCN3yjP38f3zLdK2KF8Qwh9Bi7XP/ZkI7wPTKfRZ+gQW+FdffWVQNP1EW+BNwkpHCWLjGTw63AuhJIVtCepWZzj+MvGj1yNEQLT64rgP+YCK5SMuFiFWLANksQxGxaLpFsuAkxAo7CH7oSf+396ZgNtRVHm8QEBIiAokZFERwioq+5qYQEIwbAoCIpuENUDYhsFxRnRGEUVBRHYBQVAUF4QgCAmLbDEBokFEQMKigmHVgSAMJCyv5/yanEvdun3vfet9/d77n+/r796urq6u+ld1/eucOlX90utZ3WPh4rasrMeIkSMze8EN5mqxTjkzc2hVoJnVMntxM/uUZx5uJJKXP73fOprMiCEzzNJkM9Pe8nusQ6+6ZhpKHm7aRCXcNKU8zDqaqrim3WamceVhxCeOdRKZ1VMlnnVeebh1WlX3xifWiWamHfKd4cw6l8ol8sa9pkVUwjzfRkiVMNNYMuukM5s7zMNMi8jvM6KveqZpznm4EX9VOCfWcWVmes9s0JOZJSOzDqsqjmlIOeaxkJ5ZGzLTjivBRkJ5vOnTp+dh1nHmz7QOuepeI4zMOsLMLBaVcLO4ZPZp1jw9G3Tk99kys6r7ODFTa7bJJptUhZvJtyZ/Rgh52zDtO49rJtU8TTCMxeY/M7MsZDagyINJn3immWa8X2DLuX2eNDMiqrrXBoYZZYmFdmGEVBVmg5k8f/4MM6/naRrZV+LZK55jz3MQI9k8jhFhZhpw/t8PM7lnNhCpeoatUMhsMFUVZsSX2UCgKuyMM87IzKReCSNNs2JlZlmohFkfk7cF8CsSb5s2iC66nBlxZ2ZFq1yjPk2TrXkPzHKVmTaexzNzfF4+m6LIaNMuNiDL2wp9gYsNfLLhw4fnaVIHS77TnZklrxLH/1C3vIcuZj3Ln2MDgqq4Zi3JOBBb/ZHHoT7Iu4sNrPJwszblQbzXnBvhV+Lwxz7VmofH2NtgOQ+b/+TTpe2HY34YM258pb3Z99AzGxxmNshts/bTZlM4bdam2+w9bzMFoM3esTbDrG3+/PltNohps/ekzfrNNltp02aDm5y34C/E4OnVQxq6tcLeEjQRzNSM1F3QgDHLxlo2I3/Mx7HsvvvueTzXfjtbBteG0FzjpWBo4D4n7mlbw6/SvplvYxkLWkmR2AsQxo4dm2v7mKStkyqKVgmzlyH/j/bny9wwjzM3ybx8LJiWY2GeHcG8nAplQbtFa0VLa896enDB1B1jgKkRzP1Z/px0egSc0PK8XtF+MJGjZbXHfJvmn2kVTNRYJdykizbFFEtsWsZ8TPuJBS9ycJ03b14ejFZFPWDpQYNDm0TTRdNPNds0H35OfcZLwZifBRc0fxfm72N/A6YrMAPzHNq8L8FiCRRWGCwHWDaoV6wx+As0E+aEmVfGecvbDisI0qVhaNrx/DFmZKw0c+fOLXwEmqwNqtr9iVSfvuEdwhLjggUJM3csTEvEvinghKUk7gPAAXM5mjBtn19M8V6HhZlOAmm3PjXGJZawpstYaafxlBT1xdJOzwtTCAhau7+PWGd8mqczbbk9eVecziMgQu88dl2+E0cXTLYQI05DkB5mw1QwVacOam6+jjuQ9L72nGOyxFHMRqN5R89AAVN10ZpXzLOx0JGRj6I8YDLEnMqAA1MzvgHNBG94zI2YKfnFNEq+INZURo8eXRXk8/RFzlQQBOVxEzRlhMgaCXHAnE4P8yVEEXe6fi8+A6Z1ViUV1w0DA+YpGQR4B9nouUXXMK9jSsbcDy44jYFvurkOpvzU8YkBF+LlxYkQ870PGKlDBgo4kjFv7FMWRfkgDOdDBhfMnXIP87908qlQP6mfgtcRhO4ETD4gb66BI22PdogfSTNhOoQBAniAOabmojXnRcvfwIUBHu9fLJAm0wiYotsrlJPpJtoH88043ZmmV9jG0nbLM8g7mCDMxVPfDNgwhWMyZzoEXwH6BwYNjQQnRXwXGMQywOKdwq/A58nje4vyQj14XpgawH+F6QPanVmY8sEHTpYMHmP/mkZ50rXWISBCbx3WNU9C68bj2rVYiA/nJTrNeB6xaM7VO+44Xs0D2hmA9soonHl4CJS5TDpBHIdiKcoH2k5MAuQHBz60LtYVoz2hAbZHcNhBw+Z+Okkc4SBWMEm16tR7mPk+pB4hgRdpMVigE48dEYvyxjPJO3OvaI9o1wy8mEePO0fykRKX1w15gSQhPOZi+c/hO5cxN895PA9elBeIDm2aQRGDC/IFvnSu3vlyH/WXimtg/ktaTqwel2t03lgvmu3WhjWCNgJpMQ+MXwWkzNImJ2nSTeuHMHfoAhd35sSCEONHHNJmYIuVo5HgvIWGjkc4gwy83RloMJ8dS9GKA9cu07qjPhDaSkcESwOaPWSHLwqe8WDN/HUsRbjQdr3d4i/BO4QfC74JCAMctH0kdQ6tSnzJCT4DDP4gdAYA+CfwPqcWt2Z5ITl8GuiXuJ+BNfVMnZPfooFSUX4U1joEROitw7rwSZjgMFkzCmetJ0SCgxVmZ5fY+9zDMMUhjMi7KhABnRHaLWZINB802nRgUTTKx3M4zgOdKR7oU6ZMCeYHkBNFR4ROjOVMlA/iQlOCzFPPcky8sTgeWBwwD7L2vEjLcxO1x2+UN+LiPIXpEgcqtCScE/EGdgGTmMgIj+vGMSP/5InDTfR0sJzjLNZMIGE87BkEYPWgY8X5jY7fpahMTtDNpjvc6z0luKJ8YTrHrI3WT13jyAVxxSbdtH5Ix60EWBvcqlG0mQ1hEEZ7BqtMMTAopo4gY1Z7sFNdbOkqwoW8oGGmXuNYcRgoOZkWlb8ojAECg2KeS71AggzsINPY870IF/JHu0Xc2oV1KxbKxcAkdsgsygdhPBfnSzR8BpMMqMGTgXKMabO8kBbtgvuxHDCFxqDJrWDpapZ6+VF46xAQobcO65on4RnsGgHarHsCY86CDF2Y90zNzmxrimZVtOa25kENAvBGxsuZQQPp4UXrS2noaGKNjRc6FjQ6Og1McQjmSsx7pMfI3rWwBo+vugRR+gYjdJDMczKw4TediqDTjAUzMoK2iKkcTb9IC/elS80GQnir+5I1BjxMjzDAQOuhc3NhNUI65eBbajI4Y/6W+fP4QINC0CwJbzboYX1wvLkJc/kM/mgzcQePD0RqyUBbhKQhKeqa/0U79lEmCK4R8TOPywAEDR0BQ6w5vlFOXEd4SqcDHdoHbQKyBBvIIs0v6RJGPhotrWOlBcu/KBMCMbPnAGSOxFYPBkGxuH8DmMRCmrQrpqA6IrQ9cPGyYEWBBPEiBzPeERf3IPdz3muw9ykQH2Ckg3jyzEC1yAoT5xWNnLz4IAKcGVwwoCQsnmpKcYHgyavnBUsSaaXTErxXgwcPrrsnQ0ewU9zuRUCE3r14dig1Xgzm2uKOj045NWcRFnfCro2gMRaZzTqSCUgZc146N8f8IsQYd/BoY8R3QSujw/L1x2jEaBGxBtuRvEBOONzEJAUWkHA6T828q5tk+cXkiemSOUMEnwSWBMYdIzijYUBqrOtuJMyHsjY4/oAK5E3nluYl3iQGPMAJ4sexis4dR6/48M1uIGbC0/TSfPFMBkhxWXCcogNGc4sFU6vjAqmxCRBTBeQHAoMw0q2BmVqB+NF2663L5hngiyOem3/9uU4SzB+7MMiJP4oCUdLe/RkQOxv1YGKOl8yhUULSmOIbCRot0xCpCdrn82N/D9JjMOYCJkxV4B8Ri8+/p9pxo3xwjfbEwBz/hFh8MBzjwmAoHmxg+YFosXogvq47/egP2NG2mJ5rJJA+eaHtx0IdUX/x+8z7G2vp+GXQxj0vtCPSii1I5JU5ddpwowFXozzqWs8h0HzHhJ579oBPGdMrpMF8HY4sODlBOLwozN26MHeN1osGBAmgOULq7fVKbgQ0DkVoWjgUMWKn86GjhFjJE05fLrzgDCKYv6WDIO8bbbRRHg/hxUfjYA60SLgPK0Q9wQEHEzJ5wjyIFoBZGq9q19z9XjpftF8GEzi9QTRosW7CZbMbOkGIGycjtE/Ig7ho2zgdNRI0EzpFnoFzHp02DluQKpq1C8TkDlBo2lgU0PQg+diDuNGzml0DN9oIgxTaBWZTzMwMuGLnLRy9mFOGFNBewQ6TP6Z6BO2OXb4YcEFa+HBAOpAi+GCVaCY8j7KRHwgZPCACBnL4F7hgVsf7HUsJTl8+AIv9KXDyoq0wtYG1isEb69xp/82cKCkr7Y7BBRYstEqIErKhjcaEzlwvZaXesfwwOGaglbZFt6x0lNAZKGF+9j0KeEd5l7Ci0P7Awi1DkCoDLN43yJOpLpzTfF908oiTImlRHtoUWjNtDIsM70UjwfGSeNQzmj/vM+VigMDgMfZM5z9tBRx4n7Fu4OnufQ+DYwYA5JV5c9o6bYR8p1NgjfKkay1EwLSWXl03x/MR66QG3Dp00/4ye8nydcJW5fnB2nIbFRssbwtrZe3FyswBqBLHOrzMiK8SJ/3TkXXo3GsaTGYaXCV98mEdQ752FvF16DbYyKxzrsSzTjRj/amLaU1VaXiZ/Nfm9Spxi9ahc9E66Hydr99jpJXZwIVGkt9rmni+5tm8eDMj/Dwe+Jnpt2ZNvg04MutAq/JkHWbV2nfSLFqHzvPMsz1fr+15sbnJjHXOLqxDt844s44wX0tMPH5tLrWS30rk6I8RVx63vevQuRVcHHvWx5umltmSqEqqrB2mbKYl5mudSZ/4vmbeI7K+2wZHVbgYgWVmNq7JKvWbrkM3y03Gut24zRpp5G3IxQg1s+1tMyOKCnY20KrZF8HLFdcR68NtsFKTl6J16KYtZqzvBw/Ky3thxJix34ILZTOfjDzc82wDiCze68Djkl/W2Htbq8nEkoB0HTrBNtjOfP29txfWw/teBOSJdmuD8XyfAY9j5J/fG4sNBrINN9ywqt3aNEVm/i01WaJM8Tp0Iph1KW+X/gx+TevObPCV328DzjwvNkDN95bweEbmlb0E/EHsi0GdeBzeObO81ORD69DLsQ59KauZxq6kVpM9LZaH3EzIgfbBgaZnZLaUj5ptY5kwbpsJdbNCGmWV9VZ/fzjfTMLMhRYJI3EcnRhZMyfuHttpXMyJmAox5TLq76ig1XMfI3e0vVjAnLlArAR46tbzYMX8izma0Trz7Z3VQtGkMHnyPDTxWDBzk0ffRjZdiuVxMf+hvaOF1MsvGir+BvxaJ1no7IQ2iJZZz0kIfwa0W+qmnl8AWhRzqMTxZWsdrR/iY+7EXF1vzTEaMXg1Mnei6VLeRn4COD1itmfKhrXHRUIb4Sj6LCt5pMyY8pkTr9cO8LtAO0WLTevZn8l1loqRBiblIkc5noMmGe+O6PfTJkmDOI3WRtP+waaRn0ARDmkYbYEpnqKvjfEekxemQuo9hzzwrpFXcCnCjr6QdgvG9AtYMWJrmeeJe7GMpaZ47ufdYIoM60G9toC2TV5o12mf4M9g+o32SJvBulC02oW2RDuwjWWs3CNSyEp3vtOkbcOcWXfm+aIfor4YsNPXcNBWwcR/CWO6igPLGO8f9cfBNBX1wIElrzdFJvfeRH/Js5lDbTaPSlScz9wBrbuz7ea3ZunSsDu7nrpZ2n6dl6Y9e0TTSTWbC4cccKrrrNCWqoDwAAAUr0lEQVSZxqbkeulgNi1a11svfmfD2+MzQQdTrwP359JR4TDVWcHrPl3+VpQWHWU6z5/GY5AZ7wOfXm92Tptsz/vjnuTN0uvKdcizmfc39dNsS1nIgYE7R2eE+925rdH9EFP8QZaiuAxgmF6RlB8BOcWVv46UQyEgBISAEBACTREQoTeFSBGEgBAQAkJACJQfARF6+etIORQCQkAICAEh0BQBEXpTiBRBCAgBISAEhED5ERChl7+OlEMhIASEgBAQAk0REKE3hUgRhIAQEAJCQAiUHwERegvqaOTIUYV7Vrfg0VWPYEtV1rIW7Z/d6rywthUpQ15YC8/2uvFHNFqNhz+Ptb6s8WZ9cG8L67vT/ft7I0+s22ZvgjK0Fdota7zLkBf2hWdNdBnywpf32D9j5ZW7/rGo3mhj/eWZWofegpqcOu3ocPzRb2+tyrrm3hA6RL4ktc56H8436OCrYc0+9NBT+aRTZA/rj22wYb59Jxs7pF+96qlnp+nyARq2Ph295lr55hzsNV60gUd6X0+c225b+Z7qw6yNsH0p26I22lu9J/LgabKxD9vCskkK6/DZDrU3Ns2APGfPnp1v4EH7ZctZNj7qDWHzpZm27/2wVYfnW6GyIZR/b77V+WFfd/aOX2P0muGYY47JN3tqzx4FPZFPBsRsq3zw1CN77d3piXL1xTRF6C2otX0+NyUMsz2Rr7tmepj/2DtfXmrBoyuPYAOJE/7rS+GAgw8N11x1Zbj1lpvDM8//s5VZqDxrkG1qcvrZ54Xd9vhM+NEPLg53z5ndaxrpe2wP8iuuuiaMGTsuXPS9c8OfjMja89nOngBu2LBVw4xb78w76YvOPzc8Mv/hmi+W9cRzi9Jcc931w9dPPzPvoC+58ILwyON/LYrWkrAx4yeES3/2y/CcfWL4ih/9sNfeIQZXn/7MZ8Ph044J9/1hXrj6yl/0Wl6olyOPOz4cfNgRYeb114WbZs4Iz/dS38Jg/Ounnh723v+AlrQHPaQ+Atr6tT42uiIEhIAQEAL9EIH+uvWr5tD7YWNVkYSAEBACQmDgISBCH3h1rhILASEgBIRAP0RAhN4PK1VFEgJCQAgIgYGHgAh94NW5SiwEhIAQEAL9EAERej+sVBVJCAgBISAEBh4CIvSBV+cqsRAQAkJACPRDBLQOvR9WqorUegSyLAuPPjI//PEP94bnn3s2LF682DbueW8YMXJkGDp0WPiobaKz4pAhrc9YDz3xVdvRrtludoNXXFEbjfQQ/kpWCBQhIEIvQkVhQqCdCLCT2aXfvzB875yzwmOPPlL3LnY622SzzcO4bSaEgw6bGj7wwdXqxu2uC3/9y+PhpYUL8+TWWXe9wIY+3SVHHHJguHb6VU2TW2Xo0LDRxpuGXXffI+y17/759qASISAEegYBmdx7BlelOgAQQEvdfecdwgnHHtWQzIGC3efm3n1X+M6pp4R5v5vbEnS+9IXPh2233jw/HnrwgZY8M33I//7zn+E3N98Yjj1yahizyQbhwT/dn0bRuRAQAt2EgDT0bgJSyQw8BA4/eEq4/dZbKgWfvOPOYc+99wmrrzE6fHC11XISf9a2K8UMf9tvbgm33DQzLLI99fubbDX242GrrcdWFYsph2eefioncKYikL88/lj41A6Twl1/+FNY1fZDlwgBIdC9CIjQuxdPpTZAELh79m9tb/6rK6U998KLw/4HHlxTekzrm22xZTjk8CPDy/ZRmp9cflkYPnxETby+HLDtxO3Cf335K3WLcPWVPw9HHnJg7leAxv7d004N3zz9jLrxdUEICIHOISCTe+dw010DHIFfTX+HzD+xw06FZJ5CNOQ97wlHHHVsQKMdSLK7fdDkiKOPqxT55pk3DKTiq6xCoGUISENvGdR6UH9C4C+PPVopztjx43ukaP966SUz1d8c7r/vvvCcec7zha3hI0aEceO3zQcF9T6tOv/hP4fX7FvmL730tkMcmXvUvtyGY14q6314/bC8fS2rp2Xi9tuHs75zWv6YZ555uqcfp/SFwIBEoPYNH5AwqNBCoGMI8H15l1defqVjNzeJ/crLL4dvf/Mb4cLzzymcc/9WOCmsa9+1P+3Ms8M2E7arSe3QA/azz8DeVxV+5KEH1cQj4G6bz15v/Y8UXuvOwGWXWbaS3EorrdydSSstISAEliAgk7uaghDoBAIjR42q3HXzjTO67Rvqzz77TNhxu21ybdYd6FjPDYGvtfY6FS0bLXyPXXYMP7/ix53IfetvuWvObysPpRwSISAEuh8BEXr3Y6oUBwAC20yYWCnlfffOC2jFTz7xty6VnI1a9tvz0xXt+iMf2yBcee314YnnXgj3/PHB8PsHHg6PLXgu/McXvxyWXnrpfBBxnC0He+D+P1Y9d9bce8PCxW1hp0/uWgm/ZdZdeVh6tEI7//3ce8LZZ5xeycs+nzugSzjpZiEgBIoRkMm9GBeFCoGGCOzx2X3Cd799amVJ1jVXXZl7vW+0yab55jFbbr112Ng2khkxYmTDdOKL53z39Moa9a3GjA3Tr78xrDBoUNX971tppfClr34tn0v//HFHh0WLFoWTvnxiTvy9Jffde2+47OKLqh6/aPGi8PSCt5etsbTvrbfeyq9POeSwsNc++/VWVvVcIdCvERCh9+vqVeF6CoF3v/vd4WfTrw177bpLeHyJgxykxaYx8cYxH1p9jTDetPm9bZe0seO3qZsdiPnCc8/Jr+P89r1LLqsh8/jmQ4+YFi6/7Af5GnfWty/4+5Mt2X2uqAAzr78ucDSSj5sj3+e/eGLYduKkRtF0TQgIgS4gIJN7F8DTrQMbgTXXWjvcec+8cOJXTrI929+ZU49ReeJvfw2XX3pJ2Hn7CWGHiePDI+ZtXiT33DU7PP/8c/klHN3WGL1mUbSqsN322DM/Zx/52bPubBq/NyP89s7bwze/9tV8tzyJEBACPYOANPSewVWpDhAEcFj7won/HU74zxPD3LvmhDvvuC3Mmzs315xZahYLm9FMGrd1uO7G34QNN96k+tqc2ZXzzbbcsl3oxc5ljz1Sfx/5diXWhUgHHXZ4mHLwoTUpsJEMy+Wm//LKfPvXewyfnczh7/s//HH49J571cRXgBAQAl1DQITeNfx0txDIEWBN+NYfH5cfLmjjN824Plx0/nkVhznWlh+472fD3PsfqvoS2dNPPVW571snnxQ4OiIvvvhCR6J3a1zm8/EdKJIttx6Tb7rzg4suCP9+zLTcke+oqYfkH6phOkIiBIRA9yEgk3v3YamUhEAVAnzh7Oh/OyHcc98DYd8DDqxc4yto8baxXFj44otdQg9tuMxy8NQjwphxb2/Aw0dtLljiL1DmPCtvQqCvISANva/VmPLb5xDAU/3M8y4It950Y2CdOTLrjtsDW6K6rBDt1nbcCV8IEyZ1zHms3hx+mcCaOGn7MGfJXH/8UZsy5VF5EQJ9GQERel+uPeW9zyCw3HLLhU3tIy3XX3tNnuenFyyoyvsqQ4dVzgevOLhfeoOvvPIqlTLyJTaJEBAC3YuATO7di6dSEwJ1EVh5lXcIbRlbmhbLpptvXjmddfvtddPoyIWlllqqEr2tra0jt/ZI3H/84/lKuiusUL2+vkceqESFwABDQIQ+wCpcxe09BNhRzuWD9lnVWMZvOzGwth2ZPeuO8OcHH+hyRgdFm9IsXNi1OfouZ8YSuHnmjEoyLPmTCAEh0L0IiNC7F0+lNkAQOOWkr9hyrF+E9mq+P738h1UfTJn4iU9UITV02LCw35S3P6BCmkcccmDAeaw9Us+hbuSo91duZ/lYb8rZZ3w7sAWsyy677dab2dGzhUC/REBz6P2yWlWonkbg4T8/FE475eR86dXe+30u7LjLJ8NHN9iw5hOl7O9+4Xnnmlf3WZUsbbzpZmG77SfXZPHE/zkp12L//uQT+Tr27WzN+qlnnBnQ3lOB9O+xtetX/vyn4YZrfxUefqJ2TnqrMWNsD/W37zzvrDPzzWp4dmzu5hvt9T7Dmj6z3vlzzz4bYusD8ViexudbH31kfrjG1qHfHa2zx/v/oEMPr5ecwoWAEOgkAiL0TgKn24QACLAT3Knf+Fp+DBo8OKz2odUDc+VvvvFGeMoc355a8PcqoEa9/wPh4h/9pJBE0dJ/dvWvwmdsO9mnn1qQm90/NXlSQNNmnTfp/t8rr+TXHrJrfGYVee/73ldYGZMm7xjWXmfdnFS5Z1/78Esq3fH51Eu/f2HgaI/w1birfj2jMr3QnnsURwgIgfYhIEJvH06KJQSqENh7v/0Dm8SwpSnaKIKJ/OGHHixECi2YZWonf+u0utvEciNfWLv97t+FL55wfMWkj0d4Pa/w5W25286fKjZf41n/y+tuCMcfdWRgmVh7pwcKC9DFQHa1m3LIoWHqtGNE5l3EUrcLgXoIiNDrIaNwIdAAAT5NyvHyv/4V5syelW/36prwy6Y5Q6ZDhrwnjF5rrbDBhhuFnXfdrd1fXlt11eHhksuvyPeIv/GGX5u5ek543raRJV0c59DY0by3Gjs2jLOPnrD9bD1hSuDq62fm+8TzmdUXX3ghz7NLZ9evH3TY1MC68kaC5QCrwrofXr/dZW+Unq4JASHQGAERemN8dFUINESAOejJO+6cH90teIJPO/b4/OiqMEiYOKnaEa8raU7YrjGZdyVt3SsEhEDnEJCXe+dw011CQAgIASEgBEqFgAi9VNWhzAgBISAEhIAQ6BwCIvTO4aa7hIAQEAJCQAiUCgEReqmqQ5kRAkJACAgBIdA5BEToncNNdwkBISAEhIAQKBUCIvRSVYcyIwSEgBAQAkKgcwiI0DuHm+4SAkJACAgBIVAqBETopaoOZUYICAEhIARajQCfGk6PVuehO54nQu8OFJWGEBACQkAI9DsEIHnEf8tewFITel8BseyVrPwJASEgBIRAMQKpZh6fc0dM6mXnpNISetmBK24aChUCQkAICIG+hEAjQi/iIY9fxjKWjtDLDFYZK1B5EgJCQAgIgc4jAOcsvfTS+dERci8i+87nonvuLPXHWYYMGVIp5Z233RbeeuuthqXOsqzhdV0UAkJACAiBgY0APLHgyScrIAwaNCgss8wymZN6/FuP4P3mspF6aQg91cw532KLLcIdd9yRY3faKSeHcMrAbogqvRAQAkJACHQfAnyOeNSoUeFd73pX5Yi19SLNnafHRF4mUi+tyR2Qpk2blq1l35OWCAEhIASEgBDoTgTgmMmTJ4cVVlghMw29itSd4N0Mn5rjyUcZSb00GnpcUQ7UiiuuGGbMmJGdc845S82dOzcsXLgwYC5pa2urOQj3a6Tl53G6Msl35+ugtISAEBAC5Ucg1aAh56FDh4aNN944rL322tmyyy6Lyb3qiDV2/qeE7mmmafc2GksZybX1diZ4PiQN4b755pv5XDm/b7zxRnj99dfD4sWLw6JFi8Jrr71WOV599dX8P+EcxCEuB/fasVRM/DGZi9jLUOPKgxAQAkKgZxGIiZf/8fy4EXlO5n4sv/zywQ/m1U1zD/7Lf8zzHMstt1x+T6zFx4TfsyVqnHrpNHRAjw+vAAfPR1IACvE7aTtJE3/JoCBLNPm3dwhYgodIvXHD0FUhIASEQF9GINaejReylNDhFPgELoGk4yPV2l1LL9LUy6Stl4bQAQWSdTKPR1LtIXPuIx5aPYSeaueWNtKX26fyLgSEgBAQAh1EICZcJ2R+Y0KHwF37dg3cSd3J3H+dozqYjZZELw2hU9oY+EajqVgr90FAXEGuufPLdT94hki9Je1KDxECQkAIlAKBRrziGnozLT3W0FMtnUL6M3q7wKUidAfGR0BO6j6Sik3sPufOPU7mVIrPwcekz38XEXpvNzk9XwgIASHQWgSccGMNnf+xM1xqdndN3eOkGno8UGhtaeo/rbSE7iZ3QHRyhrBjjTsmfCfzOub2imYuQq/fGHRFCAgBIdDfEEiJ17kltuo6aTuJO7mnZne/N1Y6y4RXaQg9Nlk4WIAHAUPqMZE7KTu4VIZr5mjxbmp3LV4m9zI1OeVFCAgBIdAaBFIyj7mF/3CLW4Bj87ub4GNCj83ung6liP+3plT1n1IaQo+z2IzQiRtr8L7MrcgkLzKvX/m6IgSEgBAYCAjExB7zi2vpMak7sce/TvzE9/vLROReh6UidAcdEi4idc8012Lt3LVyNPJUO+eemNQHQuNVGYWAEBACQqAagZSInUdc8061dSf5mMxlcu9Eq3Jij0k9TiYmdCdxn2dPzexunvffTmRHtwgBISAEhEAfRyDllZhHYouvE3hM5E768aDA4fB0ywBPqTR0AInBAeRU4koA5JjIReYpWjoXAkJACAgBR8AJmXPnkiJid1O8E338W0TqZUG4dISeAhODHgPJf7RuJ3Q3q8e/pCUNPUVU50JACAiBgYUAfOHi/2M+8bnx2KSekrjH8ftIL063DIiWktDrgRQDyn8n9JTMAVZEXobmpTwIASEgBMqDQErsManXI/iiOJSoHk/1ZmlLSegpWAAXk3Z87sQeE7j/d2DT894EXM8WAkJACAiB3kEgJXRyERO2n8fKY704vVOCxk8tLaE7iGn2YzLnmhO9/49/43tF6imSOhcCQkAIDBwEUo06JXc/d4IHmfS/h5UVtdJ8PrUZQKkJvd456Yi8m6Gp60JACAgBIZCSOojExF50XmbUSq2hx8Cloyu/5uEpiafnZa4E5U0ICAEhIARah0ARnxSROzkqitu6nHbsSX1GQ0+LVY+w64Wn9+tcCAgBISAEhEARYReF9QWk+iyhNwJXpN4IHV0TAkJACAgBEOirxF2v9vqMyb1eAYrC+1slFZVRYUJACAgBISAEYgRqt2ITPkJACAgBISAEhECfQ0CE3ueqTBkWAkJACAgBIVCLgAi9FhOFCAEhIASEgBDocwiI0PtclSnDQkAICAEhIARqERCh12KiECEgBISAEBACfQ4BEXqfqzJlWAgIASEgBIRALQIi9FpMFCIEhIAQEAJCoM8hAKEv7HO5VoaFgBAQAkJACAiBGIEXIfQT7HhRuAgBISAEhIAQEAJ9EgE4/IT/B1+6c/hEmK4wAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "id": "4d72697c-cfef-4ef8-a408-ebe202577c9d",
   "metadata": {},
   "source": [
    "A Siamese model when trained in a supervised paradigm consumes the data in a very specific way. Each mini-batch should be composed of two tensors. Both of these tensors should be the same shape as of your dataset. For example, in the case of MNIST, each sample is an image of 28*28 pixels. Here, as part of the augmentation we will be upscaling them to 32*32. So each input sample is a 1*32*32 tensor. The first 1 is because the images are grayscale.\n",
    "\n",
    "In our case, if want to have batches of size `b`, each batch will be: `(b*1*32*32, b*1*32*32)`. Meaning each training input will be tuple of two tensors. Each tensor will be of shape `b*1*32*32`. But there's more, the samples in each batch will of the same class as of other batch while no other sample in the batch should of that class. This is depicted in the following image:\n",
    "\n",
    "![image.png](attachment:4901ca9f-5bea-42d8-b243-36dccf402a35.png)\n",
    "\n",
    "The formal mathematical way of saying the same thing is:\n",
    "\n",
    "\\begin{equation}\n",
    "  \\forall i, j \\in B, \\begin{cases}\n",
    "    \\text{class(sa[i]) $=$ class(sb[j])}, \\:\\: & \\text{if $i = j$}\\\\\n",
    "    \\text{class(sa[i]) $\\neq$ class(sb[j])}, \\:\\: & \\text{if $i \\neq j$} &\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "The direct result of the above assumption is that the `batch_size` cannot be larger than the number of classes that we have. So here, `batch_size` could be as large as 10. I would like to reiterate that this restriction is only applicable to *supervised learning* version of a Siamese model. This does not apply once we are talking about *self-supervised learning*.\n",
    "\n",
    "This requirement is satisfied by the classes implemented in this repo seemlessly. All you need to do is to sub-class `SiameseSampleGenerator` to generate samples of a single class per each call. Here's our implementation for MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85ce8e90-da53-483b-9fc0-e9f32681388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistGenerator(SiameseSampleGenerator):\n",
    "    def __init__(self, ds, transform=None):\n",
    "        self.samples = ds\n",
    "        random.shuffle(self.samples)\n",
    "        self.counter = 0\n",
    "        self.transform = transform\n",
    "\n",
    "    def shuffle(self):\n",
    "        random.shuffle(self.samples)\n",
    "\n",
    "    def __call__(self):\n",
    "        curr = self.counter\n",
    "        self.counter = (self.counter + 1) % len(self.samples)\n",
    "        if self.transform is not None:\n",
    "            return self.transform(self.samples[curr])\n",
    "        else:\n",
    "            return self.samples[curr]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece5d337-4b8c-47ba-b330-a13b9561d139",
   "metadata": {},
   "source": [
    "Having grouped the samples by their class/label, the `MnistGenerator` class will return one sample of a specific class when called. Then, the `SiameseDataset` class will use these generators to compose batches of data match the structure explained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82e683a7-3d03-42af-a5de-fd900a316188",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "class_count = 10\n",
    "\n",
    "assert batch_size <= class_count\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.RandomAffine((-10, 10), (0.1, 0.1), (0.8, 1.2), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_samples = [[] for i in range(10)]\n",
    "for X, y in training_mnist:\n",
    "    train_samples[y].append(X)\n",
    "\n",
    "test_samples = [[] for i in range(10)]\n",
    "for X, y in test_mnist:\n",
    "    test_samples[y].append(X)\n",
    "\n",
    "# Train dataloader\n",
    "training_generators = [MnistGenerator(train_samples[i], train_transform) for i in range(class_count)]\n",
    "training_data = SiameseDataset(len(train_samples[0]), training_generators)\n",
    "train_dataloader = SiameseDataLoader(training_data, batch_size=batch_size, class_count=class_count)\n",
    "\n",
    "# Test dataloader\n",
    "test_generators = [MnistGenerator(test_samples[i], test_transform) for i in range(class_count)]\n",
    "test_data = SiameseDataset(len(test_samples[0]), test_generators)\n",
    "test_dataloader = SiameseDataLoader(test_data, batch_size=batch_size, class_count=class_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335429e2-92d6-4f76-b243-b7324f5c4f01",
   "metadata": {},
   "source": [
    "## Tower design\n",
    "\n",
    "Next, we'll define our tower model. Generally speaking, the design of the tower model is irrelevant to the Siamese model. Except fo the following requirements:\n",
    "\n",
    "1. Make sure the input shape for the tower matches the dataset samples. To be clear, the input shape of the tower should match `sa1` in the explained example above and *not* `(sa1, sb1)`.\n",
    "2. The output shape of the tower should be a one dimensional vector of your desired length. The number of elements in the vector represents the latent space that you are encoding your input into.\n",
    "3. The last requirement is very important. The output vector of the tower should be of magnitute of `1`.\n",
    "\n",
    "As long as the tower model satisfies the three conditions above, the rest of its design is arbitrary. In case of our example here, since we are dealing with images, CNN is preferred way of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56f2ef24-4b3d-4100-9a92-5e3c571daa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistCnn(nn.Module):\n",
    "    def __init__(self, latent_size):\n",
    "        super(MnistCnn, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(32 * 8 * 8, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Linear(4096, latent_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a128ab-50da-4af9-ac4b-8db9244b42d3",
   "metadata": {},
   "source": [
    "Next, we'll instantiate an object from the tower and wrap it in a Siamese model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cff4b289-243c-43df-a659-f948c595ed83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "SiameseModel(\n",
      "  (tower): MnistCnn(\n",
      "    (cnn): Sequential(\n",
      "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): ReLU()\n",
      "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "      (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (fc): Linear(in_features=4096, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Tower model\n",
    "latent_size = 3\n",
    "tower = MnistCnn(latent_size)\n",
    "# Siamese model\n",
    "siamese = SiameseModel(tower)\n",
    "\n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "print(siamese)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9b76f-d7a9-4d6e-ac3b-09d2ccdd7396",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "The training step of a Siamese model is exactly the same as any ordinary model. The only difference is that the dataloader as well as the model deal with the data in pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e760b79-8a4d-4909-9cb9-574c900690b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, regularization, optimizer, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_counter = 0\n",
    "    # The only difference is that the dataloader will return a tuple (s1, s2)\n",
    "    for batch, (s1, s2) in enumerate(dataloader):\n",
    "        s1, s2 = s1.to(device), s2.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        o1, o2 = model((s1, s2))\n",
    "        v1 = nn.functional.normalize(o1, dim=-1)\n",
    "        v2 = nn.functional.normalize(o2, dim=-1)\n",
    "        loss = loss_fn(v1, v2) + regularization(o1, o2)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_counter += 1\n",
    "\n",
    "    total_loss += loss.item()\n",
    "    total_counter += 1\n",
    "    total_loss /= total_counter\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn, device):\n",
    "    def accuracy(v1, v2):\n",
    "        scores = torch.mm(v1, v2.t())\n",
    "        m = torch.argmax(scores, dim=-1).to(v1.device)\n",
    "        i = torch.arange(len(m)).to(v1.device)\n",
    "        mark_list = torch.where(i == m, torch.tensor(1).to(v1.device), torch.tensor(0).to(v1.device))\n",
    "        mark = torch.sum(mark_list).to(v1.device)\n",
    "        return mark / len(mark_list)\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    num_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for s1, s2 in dataloader:\n",
    "            s1, s2 = s1.to(device), s2.to(device)\n",
    "            o1, o2 = model((s1, s2))\n",
    "            v1 = nn.functional.normalize(o1, dim=-1)\n",
    "            v2 = nn.functional.normalize(o2, dim=-1)\n",
    "            test_loss += loss_fn(v1, v2)\n",
    "            test_acc += accuracy(v1, v2)\n",
    "            num_batches += 1\n",
    "    test_loss /= num_batches\n",
    "    test_acc /= num_batches\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b69f3eca-d02d-49ff-a777-9e611965856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_regularization(o1, o2):\n",
    "    return 0.0\n",
    "\n",
    "def norm_regularization_1_l1(o1, o2):\n",
    "    outputs = torch.cat([o1, o2], dim=0)\n",
    "    normed = torch.nn.functional.normalize(outputs, dim=-1)\n",
    "    dist = torch.abs(outputs - normed)\n",
    "    return dist.mean()\n",
    "\n",
    "\n",
    "def norm_regularization_1_l2(o1, o2):\n",
    "    outputs = torch.cat([o1, o2], dim=0)\n",
    "    normed = torch.nn.functional.normalize(outputs, dim=-1)\n",
    "    dist = torch.square(outputs - normed)\n",
    "    return dist.mean().sqrt()\n",
    "\n",
    "\n",
    "def norm_regularization_2_l1(o1, o2):\n",
    "    outputs = torch.cat([o1, o2], dim=0)\n",
    "    vec_size = torch.sqrt(torch.sum(outputs * outputs, dim=-1, keepdim=True))\n",
    "    dist = torch.abs(vec_size - 1.0)\n",
    "    return dist.mean()\n",
    "\n",
    "\n",
    "def norm_regularization_2_l2(o1, o2):\n",
    "    outputs = torch.cat([o1, o2], dim=0)\n",
    "    vec_size = torch.sqrt(torch.sum(outputs * outputs, dim=-1, keepdim=True))\n",
    "    dist = torch.square(vec_size - 1.0)\n",
    "    return dist.mean().sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31266e34-f527-46f0-abb2-9cdab3bca4c4",
   "metadata": {},
   "source": [
    "The only thing left is to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d43668a1-b5b6-4506-b90b-e0334a738a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tower(loss_fn, regularization):\n",
    "    tower = MnistCnn(latent_size)\n",
    "    # Siamese model\n",
    "    siamese = SiameseModel(tower).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.SGD(siamese.parameters(), lr=1e-3, momentum=0.7)\n",
    "    \n",
    "    best_tower = MnistCnn(latent_size)\n",
    "    best_acc = 0\n",
    "    epochs = 20\n",
    "    for t in range(epochs):\n",
    "        print(\"--------------------------------------------------------------------------------\")\n",
    "        print(f\"Epoch {t+1}/{epochs}\")\n",
    "        train_loss = train(train_dataloader, siamese, loss_fn, regularization, optimizer, device)\n",
    "        test_loss, test_acc = test(test_dataloader, siamese, loss_fn, device)\n",
    "    \n",
    "        print(f\"Train Loss: {train_loss:>7f} \\t Test Avg Loss: {test_loss:>8f} \\t Test Avg Acc: {test_acc:>8f}\")\n",
    "        \n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            best_tower.load_state_dict(copy.deepcopy(siamese.tower.state_dict()))\n",
    "\n",
    "    return best_tower, best_acc\n",
    "    \n",
    "    print(\"--------------------------------------------------------------------------------\")\n",
    "    print(\"Training is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a1d21c2-fd45-4db2-b3d6-a90be5a4a229",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_test_data(tower, title, best_acc, project_on_sphere=False):\n",
    "    val_mnist = datasets.MNIST(\n",
    "        root=\"data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=test_transform,\n",
    "    )\n",
    "    \n",
    "    valLoader = DataLoader(val_mnist,\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        prefetch_factor=100\n",
    "    )\n",
    "    \n",
    "    encoded_data = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in valLoader:\n",
    "            output = tower(X)\n",
    "            if project_on_sphere:\n",
    "                output = nn.functional.normalize(output, dim=-1)\n",
    "            encoded_data.extend(output.cpu().numpy())\n",
    "            labels.extend(y.cpu().numpy())\n",
    "    \n",
    "    encoded_data = np.array(encoded_data)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    scatter = go.Scatter3d(\n",
    "        x=encoded_data[:, 0],\n",
    "        y=encoded_data[:, 1],\n",
    "        z=encoded_data[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(size=2, color=labels, colorscale='Viridis', opacity=0.8),\n",
    "        text=labels, \n",
    "        hoverinfo='text',\n",
    "    )\n",
    "    \n",
    "    # Create layout\n",
    "    layout = go.Layout(\n",
    "        title=f\"{title} (best accuracy on MNIST dataset: {best_acc*100:.3f}%)\",\n",
    "        scene=dict(\n",
    "            xaxis=dict(title=\"Latent Dimension 1\"),\n",
    "            yaxis=dict(title=\"Latent Dimension 2\"),\n",
    "            zaxis=dict(title=\"Latent Dimension 3\"),\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    # Create figure and add scatter plot\n",
    "    fig = go.Figure(data=[scatter], layout=layout)\n",
    "    \n",
    "    # Show the plot\n",
    "    # fig.show()\n",
    "    fig.write_html(f\"./charts/{title}.html\", auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014c505e-7aad-493f-8212-5c6560e808aa",
   "metadata": {},
   "source": [
    "Now we can use our trained model and generate the embeddings for each of the samples. Once we have the embeddings, a simple matrix multiplication will give us the cosine distance between any two samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2871843b-a272-489f-acae-3f566a7fa086",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/20\n",
      "Train Loss: 1.634827 \t Test Avg Loss: 1.017131 \t Test Avg Acc: 0.665306\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2/20\n",
      "Train Loss: 1.082375 \t Test Avg Loss: 0.921076 \t Test Avg Acc: 0.752041\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3/20\n",
      "Train Loss: 0.966656 \t Test Avg Loss: 0.845664 \t Test Avg Acc: 0.819388\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4/20\n",
      "Train Loss: 0.907769 \t Test Avg Loss: 0.758578 \t Test Avg Acc: 0.898980\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5/20\n",
      "Train Loss: 0.841190 \t Test Avg Loss: 0.742853 \t Test Avg Acc: 0.924490\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6/20\n",
      "Train Loss: 0.800408 \t Test Avg Loss: 0.723338 \t Test Avg Acc: 0.931633\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7/20\n",
      "Train Loss: 0.764714 \t Test Avg Loss: 0.684373 \t Test Avg Acc: 0.941837\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8/20\n",
      "Train Loss: 0.731088 \t Test Avg Loss: 0.656916 \t Test Avg Acc: 0.960204\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9/20\n",
      "Train Loss: 0.712861 \t Test Avg Loss: 0.637535 \t Test Avg Acc: 0.970408\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10/20\n",
      "Train Loss: 0.693559 \t Test Avg Loss: 0.672182 \t Test Avg Acc: 0.950000\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11/20\n",
      "Train Loss: 0.676651 \t Test Avg Loss: 0.653931 \t Test Avg Acc: 0.955102\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12/20\n",
      "Train Loss: 0.672807 \t Test Avg Loss: 0.627330 \t Test Avg Acc: 0.965306\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13/20\n",
      "Train Loss: 0.656193 \t Test Avg Loss: 0.607418 \t Test Avg Acc: 0.972449\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14/20\n",
      "Train Loss: 0.648938 \t Test Avg Loss: 0.612505 \t Test Avg Acc: 0.966327\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15/20\n",
      "Train Loss: 0.630627 \t Test Avg Loss: 0.581388 \t Test Avg Acc: 0.980612\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16/20\n",
      "Train Loss: 0.635255 \t Test Avg Loss: 0.576092 \t Test Avg Acc: 0.977551\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17/20\n",
      "Train Loss: 0.618789 \t Test Avg Loss: 0.569472 \t Test Avg Acc: 0.977551\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18/20\n",
      "Train Loss: 0.612609 \t Test Avg Loss: 0.595875 \t Test Avg Acc: 0.973470\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19/20\n",
      "Train Loss: 0.602029 \t Test Avg Loss: 0.571739 \t Test Avg Acc: 0.979592\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20/20\n",
      "Train Loss: 0.598622 \t Test Avg Loss: 0.564502 \t Test Avg Acc: 0.976531\n"
     ]
    }
   ],
   "source": [
    "tower, best_acc = train_tower(triplet_loss, no_regularization)\n",
    "plot_test_data(tower, \"Triplet loss function with no regularization\", best_acc)\n",
    "plot_test_data(tower, \"Triplet loss function with no regularization projected onto sphere\", best_acc, project_on_sphere=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c1c9765-a908-430b-93f2-c2cb6a43c76e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/20\n",
      "Train Loss: 2.386195 \t Test Avg Loss: 1.528862 \t Test Avg Acc: 0.416326\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2/20\n",
      "Train Loss: 2.081919 \t Test Avg Loss: 1.146600 \t Test Avg Acc: 0.675510\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3/20\n",
      "Train Loss: 1.779183 \t Test Avg Loss: 1.042387 \t Test Avg Acc: 0.704082\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4/20\n",
      "Train Loss: 1.640846 \t Test Avg Loss: 1.333198 \t Test Avg Acc: 0.666327\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5/20\n",
      "Train Loss: 1.527947 \t Test Avg Loss: 1.032391 \t Test Avg Acc: 0.728571\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6/20\n",
      "Train Loss: 1.533680 \t Test Avg Loss: 1.074842 \t Test Avg Acc: 0.654082\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7/20\n",
      "Train Loss: 1.453158 \t Test Avg Loss: 1.122869 \t Test Avg Acc: 0.672449\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8/20\n",
      "Train Loss: 1.379533 \t Test Avg Loss: 0.869648 \t Test Avg Acc: 0.845919\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9/20\n",
      "Train Loss: 1.337674 \t Test Avg Loss: 0.903183 \t Test Avg Acc: 0.821429\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10/20\n",
      "Train Loss: 1.266130 \t Test Avg Loss: 0.956719 \t Test Avg Acc: 0.810204\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11/20\n",
      "Train Loss: 1.359069 \t Test Avg Loss: 0.896305 \t Test Avg Acc: 0.845919\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12/20\n",
      "Train Loss: 1.208251 \t Test Avg Loss: 0.830504 \t Test Avg Acc: 0.891837\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13/20\n",
      "Train Loss: 1.218494 \t Test Avg Loss: 0.762873 \t Test Avg Acc: 0.922449\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14/20\n",
      "Train Loss: 1.146021 \t Test Avg Loss: 0.770256 \t Test Avg Acc: 0.918368\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15/20\n",
      "Train Loss: 1.111046 \t Test Avg Loss: 0.927692 \t Test Avg Acc: 0.882653\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16/20\n",
      "Train Loss: 1.073135 \t Test Avg Loss: 0.868622 \t Test Avg Acc: 0.890817\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17/20\n",
      "Train Loss: 1.138044 \t Test Avg Loss: 0.820297 \t Test Avg Acc: 0.901021\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18/20\n",
      "Train Loss: 1.037780 \t Test Avg Loss: 0.805498 \t Test Avg Acc: 0.895919\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19/20\n",
      "Train Loss: 1.107181 \t Test Avg Loss: 0.850895 \t Test Avg Acc: 0.883674\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20/20\n",
      "Train Loss: 1.049613 \t Test Avg Loss: 0.831077 \t Test Avg Acc: 0.884694\n"
     ]
    }
   ],
   "source": [
    "tower, best_acc = train_tower(triplet_loss, norm_regularization_1_l1)\n",
    "plot_test_data(tower, \"Triplet loss function with normalization regularization (type 1 + L1)\", best_acc)\n",
    "plot_test_data(tower, \"Triplet loss function with normalization regularization (type 1 + L1) projected onto sphere\", best_acc, project_on_sphere=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1918358c-ce0a-4ff6-afd5-53a94912e827",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/20\n",
      "Train Loss: 2.504698 \t Test Avg Loss: 1.722271 \t Test Avg Acc: 0.396939\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2/20\n",
      "Train Loss: 1.982308 \t Test Avg Loss: 1.234393 \t Test Avg Acc: 0.601020\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3/20\n",
      "Train Loss: 1.863082 \t Test Avg Loss: 1.425046 \t Test Avg Acc: 0.464286\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4/20\n",
      "Train Loss: 1.737730 \t Test Avg Loss: 1.056005 \t Test Avg Acc: 0.719388\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5/20\n",
      "Train Loss: 1.825165 \t Test Avg Loss: 1.208592 \t Test Avg Acc: 0.606122\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6/20\n",
      "Train Loss: 1.658907 \t Test Avg Loss: 1.072984 \t Test Avg Acc: 0.717347\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7/20\n",
      "Train Loss: 1.564565 \t Test Avg Loss: 1.007443 \t Test Avg Acc: 0.740816\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8/20\n",
      "Train Loss: 1.456347 \t Test Avg Loss: 0.957611 \t Test Avg Acc: 0.826531\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9/20\n",
      "Train Loss: 1.469890 \t Test Avg Loss: 1.067057 \t Test Avg Acc: 0.715306\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10/20\n",
      "Train Loss: 1.471835 \t Test Avg Loss: 1.198958 \t Test Avg Acc: 0.671428\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11/20\n",
      "Train Loss: 1.359474 \t Test Avg Loss: 0.910828 \t Test Avg Acc: 0.837755\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12/20\n",
      "Train Loss: 1.296341 \t Test Avg Loss: 1.270954 \t Test Avg Acc: 0.615306\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13/20\n",
      "Train Loss: 1.278727 \t Test Avg Loss: 1.046064 \t Test Avg Acc: 0.712245\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14/20\n",
      "Train Loss: 1.196165 \t Test Avg Loss: 0.943150 \t Test Avg Acc: 0.824490\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15/20\n",
      "Train Loss: 1.203124 \t Test Avg Loss: 0.978527 \t Test Avg Acc: 0.803061\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16/20\n",
      "Train Loss: 1.410334 \t Test Avg Loss: 0.954324 \t Test Avg Acc: 0.829592\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17/20\n",
      "Train Loss: 1.246053 \t Test Avg Loss: 0.906432 \t Test Avg Acc: 0.840816\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18/20\n",
      "Train Loss: 1.392272 \t Test Avg Loss: 0.858531 \t Test Avg Acc: 0.876531\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19/20\n",
      "Train Loss: 1.180652 \t Test Avg Loss: 0.843712 \t Test Avg Acc: 0.913266\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20/20\n",
      "Train Loss: 1.183024 \t Test Avg Loss: 0.849092 \t Test Avg Acc: 0.853062\n"
     ]
    }
   ],
   "source": [
    "tower, best_acc = train_tower(triplet_loss, norm_regularization_1_l2)\n",
    "plot_test_data(tower, \"Triplet loss function with normalization regularization (type 1 + L2)\", best_acc)\n",
    "plot_test_data(tower, \"Triplet loss function with normalization regularization (type 1 + L2) projected onto sphere\", best_acc, project_on_sphere=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95de5e1e-7f5a-4122-a4ed-37c08b719640",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/20\n",
      "Train Loss: 2.964958 \t Test Avg Loss: 1.861192 \t Test Avg Acc: 0.305102\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2/20\n",
      "Train Loss: 2.670221 \t Test Avg Loss: 1.738887 \t Test Avg Acc: 0.351020\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3/20\n",
      "Train Loss: 2.546780 \t Test Avg Loss: 1.471148 \t Test Avg Acc: 0.432653\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4/20\n",
      "Train Loss: 2.322819 \t Test Avg Loss: 1.472425 \t Test Avg Acc: 0.484694\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5/20\n",
      "Train Loss: 2.311443 \t Test Avg Loss: 1.304688 \t Test Avg Acc: 0.554082\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6/20\n",
      "Train Loss: 2.137204 \t Test Avg Loss: 1.304661 \t Test Avg Acc: 0.613265\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7/20\n",
      "Train Loss: 2.371076 \t Test Avg Loss: 1.209800 \t Test Avg Acc: 0.565306\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8/20\n",
      "Train Loss: 2.072260 \t Test Avg Loss: 1.215439 \t Test Avg Acc: 0.623469\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9/20\n",
      "Train Loss: 1.950661 \t Test Avg Loss: 1.029777 \t Test Avg Acc: 0.715306\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10/20\n",
      "Train Loss: 2.080262 \t Test Avg Loss: 1.325571 \t Test Avg Acc: 0.534694\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11/20\n",
      "Train Loss: 2.083245 \t Test Avg Loss: 1.360245 \t Test Avg Acc: 0.558163\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12/20\n",
      "Train Loss: 2.723656 \t Test Avg Loss: 1.187460 \t Test Avg Acc: 0.613265\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13/20\n",
      "Train Loss: 1.958179 \t Test Avg Loss: 1.531518 \t Test Avg Acc: 0.506123\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14/20\n",
      "Train Loss: 1.916183 \t Test Avg Loss: 1.034148 \t Test Avg Acc: 0.761224\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15/20\n",
      "Train Loss: 1.829863 \t Test Avg Loss: 1.116594 \t Test Avg Acc: 0.694898\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16/20\n",
      "Train Loss: 1.759207 \t Test Avg Loss: 1.089223 \t Test Avg Acc: 0.688775\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17/20\n",
      "Train Loss: 1.710249 \t Test Avg Loss: 1.063787 \t Test Avg Acc: 0.719388\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18/20\n",
      "Train Loss: 1.600824 \t Test Avg Loss: 1.211931 \t Test Avg Acc: 0.639796\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19/20\n",
      "Train Loss: 1.699294 \t Test Avg Loss: 1.015506 \t Test Avg Acc: 0.761224\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20/20\n",
      "Train Loss: 1.709246 \t Test Avg Loss: 0.989985 \t Test Avg Acc: 0.867347\n"
     ]
    }
   ],
   "source": [
    "tower, best_acc = train_tower(triplet_loss, norm_regularization_2_l1)\n",
    "plot_test_data(tower, \"Triplet loss function with normalization regularization (type 2 + L1)\", best_acc)\n",
    "plot_test_data(tower, \"Triplet loss function with normalization regularization (type 2 + L1) projected onto sphere\", best_acc, project_on_sphere=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68f19387-e21e-40f0-9ed1-5d584cf7bfe5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/20\n",
      "Train Loss: 3.146405 \t Test Avg Loss: 1.858734 \t Test Avg Acc: 0.278571\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2/20\n",
      "Train Loss: 2.912144 \t Test Avg Loss: 1.544876 \t Test Avg Acc: 0.408163\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3/20\n",
      "Train Loss: 2.818736 \t Test Avg Loss: 1.751738 \t Test Avg Acc: 0.358163\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4/20\n",
      "Train Loss: 2.659382 \t Test Avg Loss: 1.524286 \t Test Avg Acc: 0.428571\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5/20\n",
      "Train Loss: 2.438941 \t Test Avg Loss: 1.254163 \t Test Avg Acc: 0.480612\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6/20\n",
      "Train Loss: 2.454201 \t Test Avg Loss: 1.444784 \t Test Avg Acc: 0.430612\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7/20\n",
      "Train Loss: 2.447575 \t Test Avg Loss: 1.692588 \t Test Avg Acc: 0.350000\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8/20\n",
      "Train Loss: 2.300378 \t Test Avg Loss: 1.299022 \t Test Avg Acc: 0.521429\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9/20\n",
      "Train Loss: 2.197757 \t Test Avg Loss: 1.329885 \t Test Avg Acc: 0.501021\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10/20\n",
      "Train Loss: 2.125453 \t Test Avg Loss: 1.467708 \t Test Avg Acc: 0.493878\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11/20\n",
      "Train Loss: 2.079372 \t Test Avg Loss: 1.236761 \t Test Avg Acc: 0.616326\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12/20\n",
      "Train Loss: 2.025953 \t Test Avg Loss: 1.142040 \t Test Avg Acc: 0.630612\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13/20\n",
      "Train Loss: 1.971793 \t Test Avg Loss: 1.160085 \t Test Avg Acc: 0.644898\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14/20\n",
      "Train Loss: 1.913197 \t Test Avg Loss: 1.168469 \t Test Avg Acc: 0.673469\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15/20\n",
      "Train Loss: 1.926003 \t Test Avg Loss: 1.154834 \t Test Avg Acc: 0.613265\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16/20\n",
      "Train Loss: 2.051916 \t Test Avg Loss: 0.997761 \t Test Avg Acc: 0.784694\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17/20\n",
      "Train Loss: 1.694030 \t Test Avg Loss: 1.200931 \t Test Avg Acc: 0.571428\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18/20\n",
      "Train Loss: 1.681103 \t Test Avg Loss: 1.236056 \t Test Avg Acc: 0.717347\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19/20\n",
      "Train Loss: 1.912881 \t Test Avg Loss: 1.209046 \t Test Avg Acc: 0.727551\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20/20\n",
      "Train Loss: 1.813900 \t Test Avg Loss: 0.949126 \t Test Avg Acc: 0.748980\n"
     ]
    }
   ],
   "source": [
    "tower, best_acc = train_tower(triplet_loss, norm_regularization_2_l2)\n",
    "plot_test_data(tower, \"Triplet loss function with normalization regularization (type 2 + L2)\", best_acc)\n",
    "plot_test_data(tower, \"Triplet loss function with normalization regularization (type 2 + L2) projected onto sphere\", best_acc, project_on_sphere=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c7dac3a-0039-48bd-9041-1a2df6e5123a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/20\n",
      "Train Loss: 1.848976 \t Test Avg Loss: 1.620070 \t Test Avg Acc: 0.645918\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2/20\n",
      "Train Loss: 1.660962 \t Test Avg Loss: 1.616102 \t Test Avg Acc: 0.697959\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3/20\n",
      "Train Loss: 1.624944 \t Test Avg Loss: 1.569342 \t Test Avg Acc: 0.817347\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4/20\n",
      "Train Loss: 1.606486 \t Test Avg Loss: 1.563362 \t Test Avg Acc: 0.816326\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5/20\n",
      "Train Loss: 1.592012 \t Test Avg Loss: 1.554415 \t Test Avg Acc: 0.854082\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6/20\n",
      "Train Loss: 1.581698 \t Test Avg Loss: 1.542469 \t Test Avg Acc: 0.879592\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7/20\n",
      "Train Loss: 1.580891 \t Test Avg Loss: 1.536747 \t Test Avg Acc: 0.898980\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8/20\n",
      "Train Loss: 1.564726 \t Test Avg Loss: 1.529733 \t Test Avg Acc: 0.909184\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9/20\n",
      "Train Loss: 1.557893 \t Test Avg Loss: 1.520103 \t Test Avg Acc: 0.935715\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10/20\n",
      "Train Loss: 1.552235 \t Test Avg Loss: 1.524152 \t Test Avg Acc: 0.935715\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11/20\n",
      "Train Loss: 1.546572 \t Test Avg Loss: 1.521946 \t Test Avg Acc: 0.930613\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12/20\n",
      "Train Loss: 1.547019 \t Test Avg Loss: 1.518381 \t Test Avg Acc: 0.937755\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13/20\n",
      "Train Loss: 1.543457 \t Test Avg Loss: 1.518861 \t Test Avg Acc: 0.938776\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14/20\n",
      "Train Loss: 1.539165 \t Test Avg Loss: 1.516683 \t Test Avg Acc: 0.943878\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15/20\n",
      "Train Loss: 1.536057 \t Test Avg Loss: 1.515028 \t Test Avg Acc: 0.953062\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16/20\n",
      "Train Loss: 1.532843 \t Test Avg Loss: 1.515282 \t Test Avg Acc: 0.944898\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17/20\n",
      "Train Loss: 1.528269 \t Test Avg Loss: 1.510608 \t Test Avg Acc: 0.955102\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18/20\n",
      "Train Loss: 1.531368 \t Test Avg Loss: 1.517637 \t Test Avg Acc: 0.950000\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19/20\n",
      "Train Loss: 1.525738 \t Test Avg Loss: 1.511547 \t Test Avg Acc: 0.944898\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20/20\n",
      "Train Loss: 1.526780 \t Test Avg Loss: 1.506769 \t Test Avg Acc: 0.971429\n"
     ]
    }
   ],
   "source": [
    "tower, best_acc = train_tower(info_nce_loss, no_regularization)\n",
    "plot_test_data(tower, \"InfoNCE loss function with no regularization\", best_acc)\n",
    "plot_test_data(tower, \"InfoNCE loss function with no regularization projected onto sphere\", best_acc, project_on_sphere=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b23d8592-93f7-4356-b636-d768e9907aa3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/20\n",
      "Train Loss: 2.215929 \t Test Avg Loss: 1.733536 \t Test Avg Acc: 0.605102\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2/20\n",
      "Train Loss: 2.006292 \t Test Avg Loss: 1.674307 \t Test Avg Acc: 0.656122\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3/20\n",
      "Train Loss: 1.900822 \t Test Avg Loss: 1.644840 \t Test Avg Acc: 0.710204\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4/20\n",
      "Train Loss: 1.866944 \t Test Avg Loss: 1.629675 \t Test Avg Acc: 0.728571\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5/20\n",
      "Train Loss: 1.832375 \t Test Avg Loss: 1.601139 \t Test Avg Acc: 0.737755\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6/20\n",
      "Train Loss: 1.786305 \t Test Avg Loss: 1.689643 \t Test Avg Acc: 0.722449\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7/20\n",
      "Train Loss: 1.828801 \t Test Avg Loss: 1.660971 \t Test Avg Acc: 0.668367\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8/20\n",
      "Train Loss: 1.772237 \t Test Avg Loss: 1.575848 \t Test Avg Acc: 0.789796\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9/20\n",
      "Train Loss: 1.745669 \t Test Avg Loss: 1.586187 \t Test Avg Acc: 0.739796\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10/20\n",
      "Train Loss: 1.728190 \t Test Avg Loss: 1.595458 \t Test Avg Acc: 0.755102\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11/20\n",
      "Train Loss: 1.777420 \t Test Avg Loss: 1.599787 \t Test Avg Acc: 0.723469\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12/20\n",
      "Train Loss: 1.693809 \t Test Avg Loss: 1.577623 \t Test Avg Acc: 0.789796\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13/20\n",
      "Train Loss: 1.711985 \t Test Avg Loss: 1.577094 \t Test Avg Acc: 0.751020\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14/20\n",
      "Train Loss: 1.724395 \t Test Avg Loss: 1.670938 \t Test Avg Acc: 0.668367\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15/20\n",
      "Train Loss: 1.713803 \t Test Avg Loss: 1.556817 \t Test Avg Acc: 0.835715\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16/20\n",
      "Train Loss: 1.668570 \t Test Avg Loss: 1.568130 \t Test Avg Acc: 0.815306\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17/20\n",
      "Train Loss: 1.659784 \t Test Avg Loss: 1.548137 \t Test Avg Acc: 0.884694\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18/20\n",
      "Train Loss: 1.657967 \t Test Avg Loss: 1.554457 \t Test Avg Acc: 0.804082\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19/20\n",
      "Train Loss: 1.652089 \t Test Avg Loss: 1.540376 \t Test Avg Acc: 0.825511\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20/20\n",
      "Train Loss: 1.635808 \t Test Avg Loss: 1.543778 \t Test Avg Acc: 0.814286\n"
     ]
    }
   ],
   "source": [
    "tower, best_acc = train_tower(info_nce_loss, norm_regularization_1_l1)\n",
    "plot_test_data(tower, \"InfoNCE loss function with normalization regularization (type 1 + L1)\", best_acc)\n",
    "plot_test_data(tower, \"InfoNCE loss function with normalization regularization (type 1 + L1) projected onto sphere\", best_acc, project_on_sphere=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "242d38b3-8b79-4f7c-87cc-3b1bbda201a3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/20\n",
      "Train Loss: 2.317214 \t Test Avg Loss: 1.793377 \t Test Avg Acc: 0.529592\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2/20\n",
      "Train Loss: 2.054616 \t Test Avg Loss: 1.833704 \t Test Avg Acc: 0.519388\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3/20\n",
      "Train Loss: 1.989758 \t Test Avg Loss: 1.690820 \t Test Avg Acc: 0.645918\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4/20\n",
      "Train Loss: 1.909677 \t Test Avg Loss: 1.650348 \t Test Avg Acc: 0.700000\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5/20\n",
      "Train Loss: 1.879954 \t Test Avg Loss: 1.641451 \t Test Avg Acc: 0.763265\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6/20\n",
      "Train Loss: 1.846934 \t Test Avg Loss: 1.609273 \t Test Avg Acc: 0.752041\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7/20\n",
      "Train Loss: 1.829812 \t Test Avg Loss: 1.659520 \t Test Avg Acc: 0.746939\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8/20\n",
      "Train Loss: 1.800525 \t Test Avg Loss: 1.591387 \t Test Avg Acc: 0.777551\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9/20\n",
      "Train Loss: 1.765575 \t Test Avg Loss: 1.600932 \t Test Avg Acc: 0.759184\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10/20\n",
      "Train Loss: 1.746979 \t Test Avg Loss: 1.567126 \t Test Avg Acc: 0.802041\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11/20\n",
      "Train Loss: 1.733301 \t Test Avg Loss: 1.587390 \t Test Avg Acc: 0.774490\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12/20\n",
      "Train Loss: 1.731287 \t Test Avg Loss: 1.585965 \t Test Avg Acc: 0.819388\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13/20\n",
      "Train Loss: 1.725808 \t Test Avg Loss: 1.722229 \t Test Avg Acc: 0.795919\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14/20\n",
      "Train Loss: 1.701244 \t Test Avg Loss: 1.557300 \t Test Avg Acc: 0.867347\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15/20\n",
      "Train Loss: 1.706124 \t Test Avg Loss: 1.545213 \t Test Avg Acc: 0.890817\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16/20\n",
      "Train Loss: 1.691360 \t Test Avg Loss: 1.555269 \t Test Avg Acc: 0.855102\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17/20\n",
      "Train Loss: 1.683228 \t Test Avg Loss: 1.537308 \t Test Avg Acc: 0.891837\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18/20\n",
      "Train Loss: 1.682564 \t Test Avg Loss: 1.550329 \t Test Avg Acc: 0.864286\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19/20\n",
      "Train Loss: 1.658326 \t Test Avg Loss: 1.527534 \t Test Avg Acc: 0.936735\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20/20\n",
      "Train Loss: 1.658027 \t Test Avg Loss: 1.526865 \t Test Avg Acc: 0.921429\n"
     ]
    }
   ],
   "source": [
    "tower, best_acc = train_tower(info_nce_loss, norm_regularization_1_l2)\n",
    "plot_test_data(tower, \"InfoNCE loss function with normalization regularization (type 1 + L2)\", best_acc)\n",
    "plot_test_data(tower, \"InfoNCE loss function with normalization regularization (type 1 + L2) projected onto sphere\", best_acc, project_on_sphere=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "419657ee-5189-4636-a036-936d4c6e71e1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/20\n",
      "Train Loss: 2.563435 \t Test Avg Loss: 1.902799 \t Test Avg Acc: 0.350000\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2/20\n",
      "Train Loss: 2.358056 \t Test Avg Loss: 1.785590 \t Test Avg Acc: 0.490816\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3/20\n",
      "Train Loss: 2.150749 \t Test Avg Loss: 1.678371 \t Test Avg Acc: 0.572449\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4/20\n",
      "Train Loss: 2.080469 \t Test Avg Loss: 1.709545 \t Test Avg Acc: 0.560204\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5/20\n",
      "Train Loss: 2.136946 \t Test Avg Loss: 1.726653 \t Test Avg Acc: 0.604081\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6/20\n",
      "Train Loss: 2.001725 \t Test Avg Loss: 1.690856 \t Test Avg Acc: 0.634694\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7/20\n",
      "Train Loss: 2.003422 \t Test Avg Loss: 1.611396 \t Test Avg Acc: 0.751020\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8/20\n",
      "Train Loss: 1.927052 \t Test Avg Loss: 1.655670 \t Test Avg Acc: 0.667347\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9/20\n",
      "Train Loss: 1.949514 \t Test Avg Loss: 1.638206 \t Test Avg Acc: 0.717347\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10/20\n",
      "Train Loss: 1.904911 \t Test Avg Loss: 1.717705 \t Test Avg Acc: 0.646939\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11/20\n",
      "Train Loss: 1.950469 \t Test Avg Loss: 1.651762 \t Test Avg Acc: 0.761224\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12/20\n",
      "Train Loss: 1.875973 \t Test Avg Loss: 1.596200 \t Test Avg Acc: 0.794898\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13/20\n",
      "Train Loss: 1.879106 \t Test Avg Loss: 1.613848 \t Test Avg Acc: 0.731633\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14/20\n",
      "Train Loss: 1.854072 \t Test Avg Loss: 1.634548 \t Test Avg Acc: 0.758163\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15/20\n",
      "Train Loss: 1.833659 \t Test Avg Loss: 1.591011 \t Test Avg Acc: 0.865307\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16/20\n",
      "Train Loss: 1.836280 \t Test Avg Loss: 1.587624 \t Test Avg Acc: 0.837755\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17/20\n",
      "Train Loss: 1.803908 \t Test Avg Loss: 1.599936 \t Test Avg Acc: 0.856123\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18/20\n",
      "Train Loss: 1.805911 \t Test Avg Loss: 1.671331 \t Test Avg Acc: 0.798980\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19/20\n",
      "Train Loss: 1.790426 \t Test Avg Loss: 1.617430 \t Test Avg Acc: 0.811225\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20/20\n",
      "Train Loss: 1.785255 \t Test Avg Loss: 1.556846 \t Test Avg Acc: 0.893878\n"
     ]
    }
   ],
   "source": [
    "tower, best_acc = train_tower(info_nce_loss, norm_regularization_2_l1)\n",
    "plot_test_data(tower, \"InfoNCE loss function with normalization regularization (type 2 + L1)\", best_acc)\n",
    "plot_test_data(tower, \"InfoNCE loss function with normalization regularization (type 2 + L1) projected onto sphere\", best_acc, project_on_sphere=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8aa24eee-0aff-474e-8e84-1c52a20cb855",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/20\n",
      "Train Loss: 2.692227 \t Test Avg Loss: 1.968376 \t Test Avg Acc: 0.341837\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2/20\n",
      "Train Loss: 2.462798 \t Test Avg Loss: 1.820063 \t Test Avg Acc: 0.460204\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3/20\n",
      "Train Loss: 2.315378 \t Test Avg Loss: 1.863773 \t Test Avg Acc: 0.421429\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4/20\n",
      "Train Loss: 2.217998 \t Test Avg Loss: 1.708911 \t Test Avg Acc: 0.539796\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5/20\n",
      "Train Loss: 2.089804 \t Test Avg Loss: 1.705806 \t Test Avg Acc: 0.602041\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6/20\n",
      "Train Loss: 2.085631 \t Test Avg Loss: 1.711024 \t Test Avg Acc: 0.620408\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7/20\n",
      "Train Loss: 2.113165 \t Test Avg Loss: 1.721691 \t Test Avg Acc: 0.539796\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8/20\n",
      "Train Loss: 2.056837 \t Test Avg Loss: 1.618608 \t Test Avg Acc: 0.720408\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9/20\n",
      "Train Loss: 1.965417 \t Test Avg Loss: 1.622620 \t Test Avg Acc: 0.718367\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10/20\n",
      "Train Loss: 1.906458 \t Test Avg Loss: 1.622003 \t Test Avg Acc: 0.785714\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11/20\n",
      "Train Loss: 1.869493 \t Test Avg Loss: 1.600313 \t Test Avg Acc: 0.758164\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12/20\n",
      "Train Loss: 1.878782 \t Test Avg Loss: 1.586080 \t Test Avg Acc: 0.810204\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13/20\n",
      "Train Loss: 1.874906 \t Test Avg Loss: 1.579052 \t Test Avg Acc: 0.821429\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14/20\n",
      "Train Loss: 1.849839 \t Test Avg Loss: 1.562175 \t Test Avg Acc: 0.887756\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15/20\n",
      "Train Loss: 1.824154 \t Test Avg Loss: 1.604983 \t Test Avg Acc: 0.776531\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16/20\n",
      "Train Loss: 1.810048 \t Test Avg Loss: 1.573452 \t Test Avg Acc: 0.875510\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17/20\n",
      "Train Loss: 1.788744 \t Test Avg Loss: 1.536520 \t Test Avg Acc: 0.908164\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18/20\n",
      "Train Loss: 1.796513 \t Test Avg Loss: 1.577294 \t Test Avg Acc: 0.871429\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19/20\n",
      "Train Loss: 1.796897 \t Test Avg Loss: 1.581597 \t Test Avg Acc: 0.858164\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20/20\n",
      "Train Loss: 1.781704 \t Test Avg Loss: 1.549971 \t Test Avg Acc: 0.897960\n"
     ]
    }
   ],
   "source": [
    "tower, best_acc = train_tower(info_nce_loss, norm_regularization_2_l2)\n",
    "plot_test_data(tower, \"InfoNCE loss function with normalization regularization (type 2 + L2)\", best_acc)\n",
    "plot_test_data(tower, \"InfoNCE loss function with normalization regularization (type 2 + L2) projected onto sphere\", best_acc, project_on_sphere=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "whisper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
